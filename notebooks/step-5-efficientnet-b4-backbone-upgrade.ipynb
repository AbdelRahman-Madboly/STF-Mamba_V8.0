{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "994b1ee7-e939-4513-901f-49d0450eb7a5",
   "metadata": {},
   "source": [
    "# Step 5: EfficientNet-B4 Backbone Upgrade\n",
    "## Ablation C ‚Äî Backbone Capacity Contribution\n",
    "\n",
    "**Step 4 lesson:** Temporal modeling on weak B0 features makes things worse (0.6135 ‚Üí 0.5524).  \n",
    "The GRU amplifies noise when spatial features are not rich enough.  \n",
    "**Conclusion: need strong spatial features FIRST, temporal module SECOND.**\n",
    "\n",
    "**This notebook:** Same architecture as Step 3 (frame-level, no temporal module),  \n",
    "but upgrading from EfficientNet-B0 to EfficientNet-B4.\n",
    "\n",
    "| Model | Params | ImageNet Top-1 | Feature Dim |\n",
    "|-------|--------|---------------|-------------|\n",
    "| EfficientNet-B0 | 5.3M | 77.7% | 1280 |\n",
    "| EfficientNet-B4 | 19.3M | 83.4% | 1792 |\n",
    "\n",
    "B4 has 3.6x more parameters and 5.7% better ImageNet accuracy.  \n",
    "Richer features = better face identity representation = clearer temporal signal for Step 6.\n",
    "\n",
    "**Expected:** Celeb-DF AUC 0.72-0.78 (vs 0.6135 with B0)  \n",
    "**Paper role:** Ablation C ‚Äî proves backbone capacity is a key contributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2beaf1-ae07-4406-9f70-c0d611408824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:16:35.602682Z",
     "iopub.status.busy": "2026-02-19T13:16:35.602028Z",
     "iopub.status.idle": "2026-02-19T13:16:36.195994Z",
     "shell.execute_reply": "2026-02-19T13:16:36.195258Z",
     "shell.execute_reply.started": "2026-02-19T13:16:35.602653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Check for ECC errors and retired pages\n",
    "!nvidia-smi -q -d ECC,PAGE_RETIREMENT\n",
    "\n",
    "# 2. Check current GPU status\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a42e2-f799-4139-b878-2c92495f0747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:16:36.197683Z",
     "iopub.status.busy": "2026-02-19T13:16:36.197464Z",
     "iopub.status.idle": "2026-02-19T13:16:36.208202Z",
     "shell.execute_reply": "2026-02-19T13:16:36.207557Z",
     "shell.execute_reply.started": "2026-02-19T13:16:36.197658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_gpu_health():\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"‚ùå ERROR: GPU not detected by PyTorch.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Move a large tensor to GPU and perform a heavy operation\n",
    "        device = torch.device(\"cuda\")\n",
    "        x = torch.randn(2048, 2048, device=device)\n",
    "        y = torch.matmul(x, x)\n",
    "        torch.cuda.synchronize() # Wait for kernels to finish\n",
    "        print(f\"‚úÖ SUCCESS: {torch.cuda.get_device_name(0)} is healthy.\")\n",
    "        print(f\"VRAM Allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå HARDWARE TEST FAILED: {e}\")\n",
    "\n",
    "test_gpu_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1bcc1b-22c0-4954-b1f9-6ab14da278a7",
   "metadata": {},
   "source": [
    "## Section 1 ‚Äî Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b915adb-9ee2-43c8-8c4d-46e87b1580d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:16:36.209094Z",
     "iopub.status.busy": "2026-02-19T13:16:36.208909Z",
     "iopub.status.idle": "2026-02-19T13:16:41.061633Z",
     "shell.execute_reply": "2026-02-19T13:16:41.060928Z",
     "shell.execute_reply.started": "2026-02-19T13:16:36.209076Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, json, random, time, warnings, sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device : {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU    : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM   : {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
    "\n",
    "OUTPUT_DIR = Path('/kaggle/working/step5')\n",
    "CKPT_DIR   = OUTPUT_DIR / 'checkpoints'\n",
    "PLOTS_DIR  = OUTPUT_DIR / 'plots'\n",
    "for d in [OUTPUT_DIR, CKPT_DIR, PLOTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Outputs ‚Üí {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57465a43-0811-4adb-b5c2-31927348b4f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:16:24.869561Z",
     "iopub.status.busy": "2026-02-19T14:16:24.868816Z",
     "iopub.status.idle": "2026-02-19T14:16:24.874970Z",
     "shell.execute_reply": "2026-02-19T14:16:24.874212Z",
     "shell.execute_reply.started": "2026-02-19T14:16:24.869533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    # Data ‚Äî same as Step 3\n",
    "    'img_size':        224,\n",
    "    'n_frames':        4,\n",
    "    'n_train_real':    600,\n",
    "    'n_train_fake':    600,\n",
    "    'n_val_each':      50,\n",
    "\n",
    "    # Model ‚Äî B4 upgrade\n",
    "    'backbone':        'efficientnet_b4',\n",
    "    'dropout':         0.4,\n",
    "\n",
    "    # Training ‚Äî fixed LR (was 5e-5, too low)\n",
    "    'epochs':          25,\n",
    "    'batch_size':      24,\n",
    "    'lr':              2e-4,    # ‚Üê was 5e-5, head gets 2e-4, backbone gets 2e-5\n",
    "    'weight_decay':    1e-4,\n",
    "    'warmup_epochs':   5,       # ‚Üê was 3, longer warmup stabilizes B4 at higher LR\n",
    "    'label_smoothing': 0.0,\n",
    "}\n",
    "\n",
    "TRAIN_METHODS = ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']\n",
    "\n",
    "print(\"Config:\")\n",
    "for k, v in CFG.items():\n",
    "    print(f\"  {k:22s}: {v}\")\n",
    "print(f\"Train methods: {TRAIN_METHODS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87fdf39-41a7-4fcc-9938-b185da9f4242",
   "metadata": {},
   "source": [
    "## Section 2 ‚Äî Dataset Paths & ID-Based Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c095e-09b0-4953-9a4c-c00d83a7eb64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:16:41.070773Z",
     "iopub.status.busy": "2026-02-19T13:16:41.070422Z",
     "iopub.status.idle": "2026-02-19T13:17:08.645414Z",
     "shell.execute_reply": "2026-02-19T13:17:08.644838Z",
     "shell.execute_reply.started": "2026-02-19T13:16:41.070743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "KAGGLE_INPUT = Path('/kaggle/input')\n",
    "\n",
    "def locate_ff_root(base):\n",
    "    known = base / 'datasets' / 'xdxd003' / 'ff-c23' / 'FaceForensics++_C23'\n",
    "    if known.exists(): return known\n",
    "    for d in sorted(base.rglob('*')):\n",
    "        if d.is_dir():\n",
    "            if sum(1 for m in ['Deepfakes','Face2Face','FaceSwap'] if (d/m).exists()) >= 2:\n",
    "                return d\n",
    "    return None\n",
    "\n",
    "def locate_celeb_root(base):\n",
    "    known = base / 'datasets' / 'reubensuju' / 'celeb-df-v2'\n",
    "    if known.exists(): return known\n",
    "    for d in sorted(base.rglob('*')):\n",
    "        if d.is_dir() and (d/'Celeb-real').exists(): return d\n",
    "    return None\n",
    "\n",
    "FF_ROOT    = locate_ff_root(KAGGLE_INPUT)\n",
    "CELEB_ROOT = locate_celeb_root(KAGGLE_INPUT)\n",
    "print(f\"FF++    : {FF_ROOT}\")\n",
    "print(f\"Celeb-DF: {CELEB_ROOT}\")\n",
    "\n",
    "FF_REAL = sorted(FF_ROOT.rglob('original*/*.mp4')) if FF_ROOT else []\n",
    "if not FF_REAL and FF_ROOT:\n",
    "    FF_REAL = sorted(p for p in FF_ROOT.rglob('*.mp4') if 'original' in str(p).lower())\n",
    "\n",
    "FF_FAKE_BY_METHOD = {}\n",
    "for method in TRAIN_METHODS:\n",
    "    paths = sorted((FF_ROOT/method).glob('*.mp4')) if FF_ROOT and (FF_ROOT/method).exists() else []\n",
    "    FF_FAKE_BY_METHOD[method] = paths\n",
    "    print(f\"  FF++/{method:20s}: {len(paths)} videos\")\n",
    "print(f\"  FF++/{'real':20s}: {len(FF_REAL)} videos\")\n",
    "\n",
    "CDF_REAL, CDF_FAKE = [], []\n",
    "if CELEB_ROOT:\n",
    "    CDF_REAL = (sorted((CELEB_ROOT/'Celeb-real').glob('*.mp4')) +\n",
    "                sorted((CELEB_ROOT/'YouTube-real').glob('*.mp4')))\n",
    "    CDF_FAKE = sorted((CELEB_ROOT/'Celeb-synthesis').glob('*.mp4'))\n",
    "    print(f\"  Celeb-DF real: {len(CDF_REAL)} | fake: {len(CDF_FAKE)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f13ca-125a-4103-ada9-3ed4b2536df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:17:08.646543Z",
     "iopub.status.busy": "2026-02-19T13:17:08.646279Z",
     "iopub.status.idle": "2026-02-19T13:17:08.715535Z",
     "shell.execute_reply": "2026-02-19T13:17:08.714842Z",
     "shell.execute_reply.started": "2026-02-19T13:17:08.646522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ ID-based split ‚Äî same logic as Step 3 (proven clean) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def get_video_id(path):\n",
    "    return Path(path).stem.split('_')[0]\n",
    "\n",
    "rng = random.Random(SEED)\n",
    "all_ids = sorted(set(get_video_id(p) for p in FF_REAL))\n",
    "rng.shuffle(all_ids)\n",
    "n_train_ids = int(len(all_ids) * 0.75)\n",
    "train_ids   = set(all_ids[:n_train_ids])\n",
    "val_ids     = set(all_ids[n_train_ids:])\n",
    "print(f\"Video IDs ‚Äî train: {len(train_ids)}, val: {len(val_ids)} (zero overlap)\")\n",
    "\n",
    "n_per_method = CFG['n_train_fake'] // len(TRAIN_METHODS)\n",
    "\n",
    "train_real_pool = [p for p in FF_REAL if get_video_id(p) in train_ids]\n",
    "train_real      = rng.sample(train_real_pool, min(CFG['n_train_real'], len(train_real_pool)))\n",
    "TRAIN_DATA      = [(p, 0) for p in train_real]\n",
    "for method in TRAIN_METHODS:\n",
    "    pool   = [p for p in FF_FAKE_BY_METHOD[method] if get_video_id(p) in train_ids]\n",
    "    picked = rng.sample(pool, min(n_per_method, len(pool)))\n",
    "    TRAIN_DATA += [(p, 1) for p in picked]\n",
    "rng.shuffle(TRAIN_DATA)\n",
    "\n",
    "val_real_pool = [p for p in FF_REAL if get_video_id(p) in val_ids]\n",
    "val_real      = rng.sample(val_real_pool, min(CFG['n_val_each'], len(val_real_pool)))\n",
    "VAL_DATA      = [(p, 0) for p in val_real]\n",
    "for method in TRAIN_METHODS:\n",
    "    pool   = [p for p in FF_FAKE_BY_METHOD[method] if get_video_id(p) in val_ids]\n",
    "    picked = rng.sample(pool, min(CFG['n_val_each']//len(TRAIN_METHODS), len(pool)))\n",
    "    VAL_DATA += [(p, 1) for p in picked]\n",
    "rng.shuffle(VAL_DATA)\n",
    "\n",
    "n_cdf    = min(200, len(CDF_REAL), len(CDF_FAKE))\n",
    "CDF_TEST = ([(p,0) for p in rng.sample(CDF_REAL, n_cdf)] +\n",
    "            [(p,1) for p in rng.sample(CDF_FAKE,  n_cdf)])\n",
    "\n",
    "print(f\"Train: {sum(1 for _,l in TRAIN_DATA if l==0)} real + \"\n",
    "      f\"{sum(1 for _,l in TRAIN_DATA if l==1)} fake = {len(TRAIN_DATA)}\")\n",
    "print(f\"Val  : {sum(1 for _,l in VAL_DATA   if l==0)} real + \"\n",
    "      f\"{sum(1 for _,l in VAL_DATA   if l==1)} fake = {len(VAL_DATA)}\")\n",
    "print(f\"CDF  : {n_cdf} real + {n_cdf} fake = {len(CDF_TEST)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678337c7-9fe9-4632-a74a-61e0664ab125",
   "metadata": {},
   "source": [
    "## Section 3 ‚Äî Dataset (same as Step 3, frame-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df607d-0865-4c26-8e24-2556432f3fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:17:08.716947Z",
     "iopub.status.busy": "2026-02-19T13:17:08.716581Z",
     "iopub.status.idle": "2026-02-19T13:32:31.297731Z",
     "shell.execute_reply": "2026-02-19T13:32:31.297028Z",
     "shell.execute_reply.started": "2026-02-19T13:17:08.716919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.15, hue=0.05),\n",
    "    transforms.RandomGrayscale(p=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1)),  # ‚Üê AFTER ToTensor (needs tensor)\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# ‚îÄ‚îÄ Frame cache ‚Äî extract once, save to disk, reload instantly ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CACHE_DIR = Path('/kaggle/working/frame_cache')\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def get_cache_path(video_path, n_frames, img_size):\n",
    "    key = f\"{Path(video_path).stem}_{n_frames}_{img_size}.npz\"\n",
    "    return CACHE_DIR / key\n",
    "\n",
    "def load_frames_cached(video_path, n_frames, img_size):\n",
    "    \"\"\"Load from disk cache if exists, otherwise extract from video and cache.\"\"\"\n",
    "    cache_path = get_cache_path(video_path, n_frames, img_size)\n",
    "    \n",
    "    # Cache hit ‚Äî instant load\n",
    "    if cache_path.exists():\n",
    "        data = np.load(cache_path)\n",
    "        return [data[f'f{i}'] for i in range(len(data.files))]\n",
    "    \n",
    "    # Cache miss ‚Äî extract from video\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened(): return None\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total < 1:\n",
    "        cap.release(); return None\n",
    "    positions = np.linspace(0, total-1, n_frames, dtype=int)\n",
    "    frames = []\n",
    "    for pos in positions:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(pos))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: continue\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        h, w = frame.shape[:2]\n",
    "        frame = frame[int(h*0.05):int(h*0.95), int(w*0.10):int(w*0.90)]\n",
    "        frame = cv2.resize(frame, (img_size, img_size))\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    if not frames: return None\n",
    "    while len(frames) < n_frames: frames.append(frames[-1])\n",
    "    frames = frames[:n_frames]\n",
    "    \n",
    "    # Save to cache\n",
    "    np.savez_compressed(cache_path, **{f'f{i}': f for i, f in enumerate(frames)})\n",
    "    return frames\n",
    "\n",
    "\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, video_label_pairs, transform, n_frames, img_size):\n",
    "        self.transform = transform\n",
    "        self.items = []\n",
    "        failed = 0\n",
    "        for path, label in tqdm(video_label_pairs, ncols=80, desc='Loading'):\n",
    "            frames = load_frames_cached(str(path), n_frames, img_size)\n",
    "            if frames is None:\n",
    "                failed += 1; continue\n",
    "            for f in frames:\n",
    "                self.items.append((f, label))\n",
    "        print(f\"  {len(self.items)} frames ready ({failed} failed)\")\n",
    "\n",
    "    def __len__(self): return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame, label = self.items[idx]\n",
    "        return self.transform(frame), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "print(\"Loading frames (first run: ~15 min, subsequent runs: ~30 sec)...\")\n",
    "t0 = time.time()\n",
    "train_ds = DeepfakeDataset(TRAIN_DATA, train_tf, CFG['n_frames'], CFG['img_size'])\n",
    "val_ds   = DeepfakeDataset(VAL_DATA,   val_tf,   CFG['n_frames'], CFG['img_size'])\n",
    "cdf_ds   = DeepfakeDataset(CDF_TEST,   val_tf,   CFG['n_frames'], CFG['img_size'])\n",
    "print(f\"Done in {time.time()-t0:.1f}s\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=CFG['batch_size'],\n",
    "                          shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=CFG['batch_size'],\n",
    "                          shuffle=False, num_workers=0, pin_memory=False)\n",
    "cdf_loader   = DataLoader(cdf_ds,   batch_size=CFG['batch_size'],\n",
    "                          shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "cache_count = len(list(CACHE_DIR.glob('*.npz')))\n",
    "print(f\"Cache: {cache_count} files in {CACHE_DIR}\")\n",
    "print(f\"Train frames: {len(train_ds)} | Val: {len(val_ds)} | CDF: {len(cdf_ds)}\")\n",
    "x, y = next(iter(train_loader))\n",
    "print(f\"Batch: x={x.shape}, labels={y.unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9d19b-864c-4e8e-a832-14453ce232d9",
   "metadata": {},
   "source": [
    "## Section 4 ‚Äî Model: EfficientNet-B4\n",
    "\n",
    "EfficientNet-B4 pretrained on ImageNet-1K.  \n",
    "Feature dim: 1792 (vs 1280 for B0).  \n",
    "19.3M params (vs 5.3M for B0).  \n",
    "\n",
    "Two-layer head with stronger regularization for the larger backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c2eb7-4714-4db5-8394-bf8a9dfa7436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T13:32:31.298849Z",
     "iopub.status.busy": "2026-02-19T13:32:31.298588Z",
     "iopub.status.idle": "2026-02-19T13:32:33.237207Z",
     "shell.execute_reply": "2026-02-19T13:32:33.236423Z",
     "shell.execute_reply.started": "2026-02-19T13:32:31.298825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DeepfakeDetectorB4(nn.Module):\n",
    "    def __init__(self, dropout=CFG['dropout']):\n",
    "        super().__init__()\n",
    "\n",
    "        # EfficientNet-B4 pretrained\n",
    "        effnet = models.efficientnet_b4(\n",
    "            weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "        in_features = effnet.classifier[1].in_features  # 1792\n",
    "\n",
    "        # Replace classifier\n",
    "        effnet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=dropout * 0.5),\n",
    "            nn.Linear(512, 2),\n",
    "        )\n",
    "        self.model = effnet\n",
    "\n",
    "        # Separate backbone and head for differential LR\n",
    "        self.backbone_params = list(effnet.features.parameters())\n",
    "        self.head_params     = list(effnet.classifier.parameters())\n",
    "\n",
    "        print(f\"Backbone (B4 features): {sum(p.numel() for p in self.backbone_params)/1e6:.2f}M params\")\n",
    "        print(f\"Head:                   {sum(p.numel() for p in self.head_params)/1e6:.2f}M params\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def get_param_groups(self, base_lr):\n",
    "        return [\n",
    "            {'params': self.backbone_params, 'lr': base_lr / 10},  # very low for pretrained\n",
    "            {'params': self.head_params,     'lr': base_lr},\n",
    "        ]\n",
    "\n",
    "\n",
    "model = DeepfakeDetectorB4().to(DEVICE)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total: {total/1e6:.2f}M params on {DEVICE}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(torch.randn(2, 3, 224, 224).to(DEVICE))\n",
    "    print(f\"Forward: (2,3,224,224) ‚Üí {out.shape} ‚úì\")\n",
    "\n",
    "# VRAM check\n",
    "if torch.cuda.is_available():\n",
    "    allocated = torch.cuda.memory_allocated() / 1e9\n",
    "    print(f\"VRAM after model init: {allocated:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a610ef33-6136-4d4c-bf09-caf17f6d053e",
   "metadata": {},
   "source": [
    "## Section 5 ‚Äî Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98d8d9-4821-4703-9cea-45449b5f4cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:16:57.271999Z",
     "iopub.status.busy": "2026-02-19T14:16:57.271677Z",
     "iopub.status.idle": "2026-02-19T14:16:57.285406Z",
     "shell.execute_reply": "2026-02-19T14:16:57.284815Z",
     "shell.execute_reply.started": "2026-02-19T14:16:57.271975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=CFG['label_smoothing'])\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.get_param_groups(CFG['lr']),\n",
    "    weight_decay=CFG['weight_decay'])\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < CFG['warmup_epochs']:\n",
    "        return (epoch+1) / CFG['warmup_epochs']\n",
    "    progress = (epoch - CFG['warmup_epochs']) / max(1, CFG['epochs'] - CFG['warmup_epochs'])\n",
    "    return 0.5 * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss   = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct    += (logits.detach().argmax(1) == y).sum().item()\n",
    "        total      += y.size(0)\n",
    "    return total_loss / len(loader), correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_labels, all_probs = [], []\n",
    "    total_loss, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y   = x.to(DEVICE), y.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            total_loss += criterion(logits, y).item()\n",
    "            probs  = F.softmax(logits, dim=1)[:, 1]\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            n += 1\n",
    "    labels = np.array(all_labels)\n",
    "    probs  = np.array(all_probs)\n",
    "    auc    = roc_auc_score(labels, probs) if len(np.unique(labels)) > 1 else 0.5\n",
    "    acc    = ((probs > 0.5).astype(int) == labels).mean()\n",
    "    return {'auc': auc, 'acc': acc, 'loss': total_loss/max(n,1),\n",
    "            'labels': labels, 'probs': probs}\n",
    "\n",
    "print(f\"‚úÖ Ready ‚Äî {len(train_loader)} steps/epoch, LR={CFG['lr']:.1e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bb909-94a5-445d-b9f7-2bbfaa48e5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:22:13.400569Z",
     "iopub.status.busy": "2026-02-19T14:22:13.399763Z",
     "iopub.status.idle": "2026-02-19T14:55:52.240658Z",
     "shell.execute_reply": "2026-02-19T14:55:52.239978Z",
     "shell.execute_reply.started": "2026-02-19T14:22:13.400538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc, math\n",
    "\n",
    "# ‚îÄ‚îÄ DataParallel for dual T4 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct, total, skipped = 0.0, 0, 0, 0\n",
    "    pbar = tqdm(loader, ncols=80, desc='  train', leave=False)\n",
    "    for x, y in pbar:\n",
    "        try:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss   = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct    += (logits.detach().argmax(1) == y).sum().item()\n",
    "            total      += y.size(0)\n",
    "            pbar.set_postfix(loss=f'{loss.item():.4f}',\n",
    "                             acc=f'{correct/total:.3f}')\n",
    "        except Exception:\n",
    "            skipped += 1\n",
    "            gc.collect()\n",
    "            continue\n",
    "    if skipped:\n",
    "        print(f\"  ‚ö†Ô∏è  {skipped} batches skipped (GPU error)\")\n",
    "    if total == 0:\n",
    "        return float('nan'), 0.0\n",
    "    return total_loss / max(len(loader) - skipped, 1), correct / total\n",
    "\n",
    "\n",
    "history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_auc':[], 'lr':[]}\n",
    "best_val_auc, best_epoch = 0.0, 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"=\"*68)\n",
    "print(f\"{'Ep':>3} {'TrLoss':>8} {'TrAcc':>7} {'VaLoss':>8} \"\n",
    "      f\"{'VaAUC':>7} {'VaAcc':>7} {'LR':>9} {'t':>5}\")\n",
    "print(\"=\"*68)\n",
    "\n",
    "for epoch in range(CFG['epochs']):\n",
    "    t0 = time.time()\n",
    "    print(f\"Epoch {epoch+1}/{CFG['epochs']}\")\n",
    "    tr_loss, tr_acc = train_epoch(model, train_loader)\n",
    "    val_m           = evaluate(model, val_loader)\n",
    "    scheduler.step()\n",
    "    lr = optimizer.param_groups[1]['lr']\n",
    "\n",
    "    history['train_loss'].append(tr_loss)\n",
    "    history['train_acc'].append(tr_acc)\n",
    "    history['val_loss'].append(val_m['loss'])\n",
    "    history['val_auc'].append(val_m['auc'])\n",
    "    history['lr'].append(lr)\n",
    "\n",
    "    flag = ' ‚úì' if val_m['auc'] > best_val_auc else ''\n",
    "    print(f\"{epoch+1:>3} {tr_loss:>8.4f} {tr_acc:>7.3f} {val_m['loss']:>8.4f} \"\n",
    "          f\"{val_m['auc']:>7.4f} {val_m['acc']:>7.3f} {lr:>9.2e} \"\n",
    "          f\"{time.time()-t0:>4.0f}s{flag}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if val_m['auc'] > best_val_auc:\n",
    "        best_val_auc = val_m['auc']\n",
    "        best_epoch   = epoch + 1\n",
    "        # DataParallel wraps the model ‚Äî save the inner module\n",
    "        state = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "        torch.save({'epoch': epoch, 'model_state': state,\n",
    "                    'val_auc': best_val_auc, 'cfg': CFG},\n",
    "                   CKPT_DIR / 'best.pth')\n",
    "\n",
    "    if math.isnan(tr_loss):\n",
    "        print(\"‚ùå NaN loss ‚Äî GPU fully dead, stopping.\")\n",
    "        break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\"*68)\n",
    "print(f\"Best val AUC : {best_val_auc:.4f} at epoch {best_epoch}\")\n",
    "print(f\"Total time   : {total_time/60:.1f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f016700-83f0-4b4d-9024-d27de6362367",
   "metadata": {},
   "source": [
    "## Section 6 ‚Äî Evaluation & Full Ablation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54ca7b-da12-45aa-addb-7ffaab32870b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:58:01.873106Z",
     "iopub.status.busy": "2026-02-19T14:58:01.872803Z",
     "iopub.status.idle": "2026-02-19T14:58:12.325433Z",
     "shell.execute_reply": "2026-02-19T14:58:12.324782Z",
     "shell.execute_reply.started": "2026-02-19T14:58:01.873081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ckpt = torch.load(CKPT_DIR / 'best.pth', map_location=DEVICE, weights_only=False)\n",
    "\n",
    "# Handle DataParallel vs plain model mismatch\n",
    "state_dict = ckpt['model_state']\n",
    "if hasattr(model, 'module'):\n",
    "    # model is DataParallel ‚Äî checkpoint was saved as plain ‚Üí add module. prefix\n",
    "    from collections import OrderedDict\n",
    "    new_state = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_state['module.' + k] = v\n",
    "    model.load_state_dict(new_state)\n",
    "else:\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "print(f\"Loaded best model ‚Äî epoch {ckpt['epoch']+1}, val AUC={ckpt['val_auc']:.4f}\")\n",
    "\n",
    "ff_m  = evaluate(model, val_loader)\n",
    "cdf_m = evaluate(model, cdf_loader)\n",
    "\n",
    "ABLATION = {\n",
    "    'Step 3 ‚Äî B0, frame-level':   {'ff': 0.6850, 'cdf': 0.6135},\n",
    "    'Step 4 ‚Äî B0 + temporal GRU': {'ff': 0.5954, 'cdf': 0.5524},\n",
    "    'Step 5 ‚Äî B4, frame-level':   {'ff': ff_m['auc'], 'cdf': cdf_m['auc']},\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"ABLATION TABLE ‚Äî ALL STEPS\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'Model':<35} {'FF++ Val':>10} {'Celeb-DF':>10} {'Delta vs S3':>12}\")\n",
    "print(\"-\"*65)\n",
    "for name, vals in ABLATION.items():\n",
    "    delta = vals['cdf'] - 0.6135\n",
    "    print(f\"{name:<35} {vals['ff']:>10.4f} {vals['cdf']:>10.4f} {delta:>+12.4f}\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "b4_gain = cdf_m['auc'] - 0.6135\n",
    "if b4_gain >= 0.08:\n",
    "    verdict = \"üü¢ STRONG B4 ‚Äî Ready to add temporal module in Step 6\"\n",
    "elif b4_gain >= 0.04:\n",
    "    verdict = \"üü° GOOD B4 ‚Äî Solid improvement. Step 6 temporal should push further\"\n",
    "else:\n",
    "    verdict = \"üü° MODEST B4 ‚Äî Consider more epochs or larger training set\"\n",
    "print(f\"\\n{verdict}\")\n",
    "print(f\"\\nB4 backbone contribution: {b4_gain:+.4f} vs B0 frame-level baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64743b96-e4c2-4fc3-86c8-65d636e3a100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:58:13.185592Z",
     "iopub.status.busy": "2026-02-19T14:58:13.185320Z",
     "iopub.status.idle": "2026-02-19T14:58:14.051895Z",
     "shell.execute_reply": "2026-02-19T14:58:14.051116Z",
     "shell.execute_reply.started": "2026-02-19T14:58:13.185573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Step 5: EfficientNet-B4 Backbone ‚Äî Training Curves & Ablation',\n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "x = range(1, len(history['train_loss'])+1)\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(x, history['train_loss'], color='#3498db', linewidth=2, label='Train')\n",
    "axes[0].plot(x, history['val_loss'],   color='#e74c3c', linewidth=2, label='Val')\n",
    "axes[0].axhline(0.693, color='gray', linestyle=':', alpha=0.5, label='Random')\n",
    "axes[0].set_title('Loss'); axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# AUC with all reference lines\n",
    "axes[1].plot(x, history['val_auc'], color='#2ecc71', linewidth=2.5, label='B4 Val AUC')\n",
    "axes[1].axhline(best_val_auc, color='#2ecc71', linestyle='--', alpha=0.5,\n",
    "                label=f'B4 best={best_val_auc:.4f}')\n",
    "axes[1].axhline(cdf_m['auc'], color='#e74c3c', linestyle='--', alpha=0.8,\n",
    "                label=f'B4 CDF={cdf_m[\"auc\"]:.4f}')\n",
    "axes[1].axhline(0.6135, color='gray', linestyle=':', alpha=0.6,\n",
    "                label='B0 CDF=0.6135 (Step3)')\n",
    "axes[1].set_title('Val AUC'); axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylim(0.40, 1.0); axes[1].legend(fontsize=8); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Ablation bar chart\n",
    "# Ablation bar chart\n",
    "names = ['B0\\nframe\\n(Step3)', 'B0+GRU\\n(Step4)', 'B4\\nframe\\n(Step5)']\n",
    "cdf_scores = [0.6135, 0.5524, cdf_m['auc']]\n",
    "colors = ['#95a5a6', '#e74c3c', '#2ecc71']\n",
    "bars = axes[2].bar(names, cdf_scores, color=colors, alpha=0.8, edgecolor='black', linewidth=0.8)\n",
    "axes[2].axhline(0.6135, color='gray', linestyle='--', alpha=0.5)\n",
    "for bar, val in zip(bars, cdf_scores):\n",
    "    axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                 f'{val:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "axes[2].set_title('Ablation: Celeb-DF AUC')\n",
    "axes[2].set_ylabel('AUC'); axes[2].set_ylim(0.40, 0.90)\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'step5_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ step5_results.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5084ab0-6fbc-40b5-a28a-03b24b2a9dce",
   "metadata": {},
   "source": [
    "## Section 7 ‚Äî Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4fe08-ff61-4379-ad00-0fcf70e50530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-19T14:58:20.009897Z",
     "iopub.status.busy": "2026-02-19T14:58:20.009337Z",
     "iopub.status.idle": "2026-02-19T14:58:20.018308Z",
     "shell.execute_reply": "2026-02-19T14:58:20.017763Z",
     "shell.execute_reply.started": "2026-02-19T14:58:20.009869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'model':           'EfficientNet-B4 ImageNet pretrained, frame-level',\n",
    "    'backbone':        'efficientnet_b4',\n",
    "    'n_frames':        CFG['n_frames'],\n",
    "    'train_methods':   TRAIN_METHODS,\n",
    "    'best_epoch':      best_epoch,\n",
    "    'ff_val':          {'auc': round(ff_m['auc'],  4), 'acc': round(ff_m['acc'],  4)},\n",
    "    'celeb_df':        {'auc': round(cdf_m['auc'], 4), 'acc': round(cdf_m['acc'], 4)},\n",
    "    'b0_baseline_cdf': 0.6135,\n",
    "    'b4_improvement':  round(cdf_m['auc'] - 0.6135, 4),\n",
    "    'training_minutes': round(total_time/60, 1),\n",
    "    'ablation': {\n",
    "        'step3_b0_frame':   {'cdf': 0.6135, 'ff': 0.6850},\n",
    "        'step4_b0_gru':     {'cdf': 0.5524, 'ff': 0.5954},\n",
    "        'step5_b4_frame':   {'cdf': round(cdf_m['auc'],4), 'ff': round(ff_m['auc'],4)},\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'step5_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 5 COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  B0 frame-level (Step 3): CDF AUC = 0.6135\")\n",
    "print(f\"  B0 + GRU       (Step 4): CDF AUC = 0.5524\")\n",
    "print(f\"  B4 frame-level (Step 5): CDF AUC = {cdf_m['auc']:.4f}\")\n",
    "print(f\"  B4 backbone gain        : {results['b4_improvement']:+.4f}\")\n",
    "print()\n",
    "print(\"Next: Step 6 ‚Äî Add temporal Mamba module on top of B4\")\n",
    "print(\"      Expected: +5-10% additional improvement\")\n",
    "print(f\"\\n‚úÖ Results ‚Üí {OUTPUT_DIR / 'step5_results.json'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 5454468,
     "datasetId": 3120670,
     "sourceId": 5380830,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10408999,
     "datasetId": 6248577,
     "sourceId": 10125851,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
