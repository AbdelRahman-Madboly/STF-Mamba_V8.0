{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STF-Mamba V8.0 — Preprocessing (CPU Only)\n",
    "\n",
    "**Purpose:** Extract face crops + build SBI cache → save as Kaggle dataset.\n",
    "\n",
    "**Settings:** CPU only (no GPU needed), Internet ON.\n",
    "\n",
    "**Attached datasets:**\n",
    "- `ff-c23` (FaceForensics++ C23)\n",
    "- `shape-predictor81` (dlib landmarks)\n",
    "\n",
    "**Output:** `/kaggle/working/stf_cache/` → upload as Kaggle dataset `stf-mamba-v8-cache`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T13:31:12.874420Z",
     "iopub.status.busy": "2026-02-20T13:31:12.873886Z",
     "iopub.status.idle": "2026-02-20T13:31:18.903868Z",
     "shell.execute_reply": "2026-02-20T13:31:18.902400Z",
     "shell.execute_reply.started": "2026-02-20T13:31:12.874371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 1: Install dependencies (CPU only — no mamba needed)\n",
    "# ============================================================================\n",
    "!pip install dlib imutils albumentations einops opencv-python-headless -q\n",
    "import os, sys, time\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T13:31:18.906702Z",
     "iopub.status.busy": "2026-02-20T13:31:18.906322Z",
     "iopub.status.idle": "2026-02-20T13:31:28.069848Z",
     "shell.execute_reply": "2026-02-20T13:31:28.068596Z",
     "shell.execute_reply.started": "2026-02-20T13:31:18.906635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 2: Clone repo + configure paths\n",
    "# ============================================================================\n",
    "REPO_URL = \"https://github.com/AbdelRahman-Madboly/STF-Mamba_V8.0.git\"\n",
    "REPO_DIR = \"/kaggle/working/STF-Mamba_V8.0\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    print(f\"Repo exists at {REPO_DIR}\")\n",
    "\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "from data.splits import load_all_splits, get_video_ids\n",
    "from data.preprocessing import FacePreprocessor\n",
    "from data.sbi_dataset import SBIVideoDataset\n",
    "from data.augmentation import get_train_transforms, get_val_transforms\n",
    "\n",
    "print(\"✓ Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T13:31:28.071557Z",
     "iopub.status.busy": "2026-02-20T13:31:28.071112Z",
     "iopub.status.idle": "2026-02-20T13:31:28.379064Z",
     "shell.execute_reply": "2026-02-20T13:31:28.378078Z",
     "shell.execute_reply.started": "2026-02-20T13:31:28.071522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 3: Dataset paths (HARDCODED — verified correct)\n",
    "# ============================================================================\n",
    "\n",
    "# FF++ ORIGINAL real videos\n",
    "FF_VIDEO_DIR = \"/kaggle/input/datasets/xdxd003/ff-c23/FaceForensics++_C23/original\"\n",
    "\n",
    "# dlib predictor\n",
    "PREDICTOR_PATH = \"/kaggle/working/shape_predictor_81_face_landmarks.dat\"\n",
    "src = \"/kaggle/input/datasets/zeyadkhalid/shape-predictor81/shape_predictor_81_face_landmarks.dat\"\n",
    "if not os.path.exists(PREDICTOR_PATH) and os.path.exists(src):\n",
    "    os.system(f\"cp '{src}' '{PREDICTOR_PATH}'\")\n",
    "\n",
    "# Output cache directory (will become Kaggle dataset)\n",
    "CACHE_DIR = \"/kaggle/working/stf_cache\"\n",
    "os.makedirs(os.path.join(CACHE_DIR, \"crops\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(CACHE_DIR, \"sbi_seed42\"), exist_ok=True)\n",
    "\n",
    "# Verify\n",
    "SPLITS_DIR = os.path.join(REPO_DIR, \"splits\")\n",
    "splits = load_all_splits(SPLITS_DIR)\n",
    "train_ids = get_video_ids(splits['train'])\n",
    "val_ids = get_video_ids(splits['val'])\n",
    "test_ids = get_video_ids(splits['test'])\n",
    "all_ids = sorted(set(train_ids + val_ids + test_ids))\n",
    "\n",
    "mp4s = [f for f in os.listdir(FF_VIDEO_DIR) if f.endswith('.mp4')]\n",
    "found = sum(1 for v in train_ids[:10] if os.path.exists(os.path.join(FF_VIDEO_DIR, f\"{v}.mp4\")))\n",
    "\n",
    "print(f\"FF++ videos: {len(mp4s)} at {FF_VIDEO_DIR}\")\n",
    "print(f\"ID check: {found}/10 ✓\" if found >= 8 else f\"WARNING: only {found}/10!\")\n",
    "print(f\"Predictor: {'✓' if os.path.exists(PREDICTOR_PATH) else '✗'}\")\n",
    "print(f\"Splits: train={len(splits['train'])}, val={len(splits['val'])}, test={len(splits['test'])}\")\n",
    "print(f\"Total unique video IDs: {len(all_ids)}\")\n",
    "print(f\"\\n✓ Cell 3 complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T13:31:28.381517Z",
     "iopub.status.busy": "2026-02-20T13:31:28.381209Z",
     "iopub.status.idle": "2026-02-20T15:55:47.087529Z",
     "shell.execute_reply": "2026-02-20T15:55:47.085817Z",
     "shell.execute_reply.started": "2026-02-20T13:31:28.381488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 4: Phase A — Extract face crops (PARALLEL — 4 workers)\n",
    "# ============================================================================\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "NUM_FRAMES = 32\n",
    "IMG_SIZE = 224\n",
    "CROP_DIR = os.path.join(CACHE_DIR, \"crops\")\n",
    "\n",
    "def process_one_video(vid_id, video_dir, crop_dir, num_frames, img_size, predictor_path):\n",
    "    \"\"\"Process a single video — runs in subprocess.\"\"\"\n",
    "    import cv2, numpy as np, dlib\n",
    "    from imutils import face_utils\n",
    "    \n",
    "    crop_path = os.path.join(crop_dir, f\"{vid_id}_crops.npz\")\n",
    "    land_path = os.path.join(crop_dir, f\"{vid_id}_landmarks.npz\")\n",
    "    if os.path.exists(crop_path) and os.path.exists(land_path):\n",
    "        return vid_id, \"cached\"\n",
    "    \n",
    "    # Find video\n",
    "    video_path = os.path.join(video_dir, f\"{vid_id}.mp4\")\n",
    "    if not os.path.exists(video_path):\n",
    "        return vid_id, \"not_found\"\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total < 1:\n",
    "        cap.release()\n",
    "        return vid_id, \"empty\"\n",
    "    \n",
    "    frame_idxs = np.linspace(0, total - 1, num_frames, endpoint=True, dtype=int)\n",
    "    \n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    \n",
    "    crops_list, landmarks_list = [], []\n",
    "    \n",
    "    for idx in frame_idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        h, w = frame_rgb.shape[:2]\n",
    "        \n",
    "        faces = detector(frame_rgb, 0)  # upsample=0 (faster, faces are large in FF++)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            # Center crop fallback\n",
    "            s = min(h, w)\n",
    "            y0, x0 = (h - s) // 2, (w - s) // 2\n",
    "            crop = cv2.resize(frame_rgb[y0:y0+s, x0:x0+s], (img_size, img_size))\n",
    "            landmark = np.zeros((81, 2), dtype=np.float32)\n",
    "        else:\n",
    "            face = max(faces, key=lambda f: (f.right()-f.left()) * (f.bottom()-f.top()))\n",
    "            shape = predictor(frame_rgb, face)\n",
    "            landmark = face_utils.shape_to_np(shape).astype(np.float32)\n",
    "            \n",
    "            x0l, y0l = landmark[:, 0].min(), landmark[:, 1].min()\n",
    "            x1l, y1l = landmark[:, 0].max(), landmark[:, 1].max()\n",
    "            cx, cy = (x0l + x1l) / 2, (y0l + y1l) / 2\n",
    "            half = max(x1l - x0l, y1l - y0l) * 1.3 / 2\n",
    "            \n",
    "            x0c = max(0, int(cx - half))\n",
    "            y0c = max(0, int(cy - half))\n",
    "            x1c = min(w, int(cx + half))\n",
    "            y1c = min(h, int(cy + half))\n",
    "            crop = cv2.resize(frame_rgb[y0c:y1c, x0c:x1c], (img_size, img_size))\n",
    "        \n",
    "        crops_list.append(crop)\n",
    "        landmarks_list.append(landmark)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Pad if needed\n",
    "    while len(crops_list) < num_frames:\n",
    "        crops_list.append(crops_list[-1] if crops_list else np.zeros((img_size, img_size, 3), dtype=np.uint8))\n",
    "        landmarks_list.append(landmarks_list[-1] if landmarks_list else np.zeros((81, 2), dtype=np.float32))\n",
    "    \n",
    "    crops = np.stack(crops_list[:num_frames])\n",
    "    landmarks = np.stack(landmarks_list[:num_frames])\n",
    "    \n",
    "    np.savez_compressed(crop_path, crops=crops)\n",
    "    np.savez_compressed(land_path, landmarks=landmarks)\n",
    "    return vid_id, \"done\"\n",
    "\n",
    "# How many CPUs?\n",
    "N_WORKERS = min(mp.cpu_count(), 4)\n",
    "print(f\"Using {N_WORKERS} parallel workers (CPUs: {mp.cpu_count()})\")\n",
    "print(f\"Videos: {len(all_ids)}, Frames/video: {NUM_FRAMES}\")\n",
    "print(f\"Output: {CROP_DIR}\")\n",
    "print()\n",
    "\n",
    "# Filter out already cached\n",
    "to_process = [v for v in all_ids if not os.path.exists(os.path.join(CROP_DIR, f\"{v}_crops.npz\"))]\n",
    "already_cached = len(all_ids) - len(to_process)\n",
    "print(f\"Already cached: {already_cached}, To process: {len(to_process)}\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "if to_process:\n",
    "    worker_fn = partial(\n",
    "        process_one_video,\n",
    "        video_dir=FF_VIDEO_DIR,\n",
    "        crop_dir=CROP_DIR,\n",
    "        num_frames=NUM_FRAMES,\n",
    "        img_size=IMG_SIZE,\n",
    "        predictor_path=PREDICTOR_PATH,\n",
    "    )\n",
    "    \n",
    "    done, failed = 0, 0\n",
    "    with mp.Pool(N_WORKERS) as pool:\n",
    "        for vid_id, status in pool.imap_unordered(worker_fn, to_process):\n",
    "            if status == \"done\":\n",
    "                done += 1\n",
    "            else:\n",
    "                failed += 1\n",
    "            total_done = done + already_cached\n",
    "            if (done + failed) % 50 == 0 or (done + failed) == len(to_process):\n",
    "                elapsed = time.time() - t0\n",
    "                rate = done / elapsed if elapsed > 0 else 0\n",
    "                eta = (len(to_process) - done - failed) / rate / 60 if rate > 0 else 0\n",
    "                print(f\"  [{total_done}/{len(all_ids)}] {rate:.1f} vid/s, ETA: {eta:.0f} min\")\n",
    "    \n",
    "    print(f\"\\nProcessed: {done}, Failed: {failed}\")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "n_crops = len([f for f in os.listdir(CROP_DIR) if f.endswith(\"_crops.npz\")])\n",
    "print(f\"Face crops done: {n_crops} videos in {elapsed/60:.1f} min\")\n",
    "print(f\"✓ Phase A complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:55:47.090607Z",
     "iopub.status.busy": "2026-02-20T15:55:47.090062Z",
     "iopub.status.idle": "2026-02-20T15:59:38.933600Z",
     "shell.execute_reply": "2026-02-20T15:59:38.932062Z",
     "shell.execute_reply.started": "2026-02-20T15:55:47.090521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 5: Phase B — Build SBI fake cache (train + val)\n",
    "# ============================================================================\n",
    "# SBI only needed for train and val (test uses Celeb-DF, not SBI)\n",
    "\n",
    "train_tf = get_train_transforms(IMG_SIZE)\n",
    "val_tf = get_val_transforms(IMG_SIZE)\n",
    "\n",
    "train_ds = SBIVideoDataset(\n",
    "    split_path=os.path.join(SPLITS_DIR, \"Dataset_Split_train.json\"),\n",
    "    video_dir=FF_VIDEO_DIR,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    phase=\"train\",\n",
    "    num_frames=NUM_FRAMES,\n",
    "    img_size=IMG_SIZE,\n",
    "    transform=train_tf,\n",
    "    sbi_seed=42,\n",
    "    predictor_path=PREDICTOR_PATH,\n",
    ")\n",
    "\n",
    "val_ds = SBIVideoDataset(\n",
    "    split_path=os.path.join(SPLITS_DIR, \"Dataset_Split_val.json\"),\n",
    "    video_dir=FF_VIDEO_DIR,\n",
    "    cache_dir=CACHE_DIR,\n",
    "    phase=\"val\",\n",
    "    num_frames=NUM_FRAMES,\n",
    "    img_size=IMG_SIZE,\n",
    "    transform=val_tf,\n",
    "    sbi_seed=42,\n",
    "    predictor_path=PREDICTOR_PATH,\n",
    ")\n",
    "\n",
    "print(f\"Building SBI cache for {len(train_ds.pairs)} train + {len(val_ds.pairs)} val pairs...\")\n",
    "print(f\"Output: {CACHE_DIR}/sbi_seed42/\")\n",
    "print()\n",
    "\n",
    "t0 = time.time()\n",
    "train_ds.build_cache(show_progress=True)\n",
    "val_ds.build_cache(show_progress=True)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "n_sbi = len([f for f in os.listdir(os.path.join(CACHE_DIR, \"sbi_seed42\")) if f.endswith(\".npz\")])\n",
    "print(f\"\\nSBI cache done: {n_sbi} files in {elapsed/60:.1f} min\")\n",
    "print(f\"✓ Phase B complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:59:38.936287Z",
     "iopub.status.busy": "2026-02-20T15:59:38.935877Z",
     "iopub.status.idle": "2026-02-20T15:59:39.495409Z",
     "shell.execute_reply": "2026-02-20T15:59:39.494215Z",
     "shell.execute_reply.started": "2026-02-20T15:59:38.936258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 6: Sanity check + cache stats\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "\n",
    "# Check a sample\n",
    "sample = train_ds[0]\n",
    "print(\"Sanity check:\")\n",
    "print(f\"  frames: {sample['frames'].shape}\")\n",
    "print(f\"  label:  {sample['label']}\")\n",
    "print(f\"  id:     {sample['video_id']}\")\n",
    "\n",
    "# Cache size\n",
    "total_size = 0\n",
    "for root, dirs, files in os.walk(CACHE_DIR):\n",
    "    for f in files:\n",
    "        total_size += os.path.getsize(os.path.join(root, f))\n",
    "\n",
    "n_crops = len([f for f in os.listdir(os.path.join(CACHE_DIR, \"crops\")) if f.endswith(\".npz\")])\n",
    "n_sbi = len([f for f in os.listdir(os.path.join(CACHE_DIR, \"sbi_seed42\")) if f.endswith(\".npz\")])\n",
    "\n",
    "print(f\"\\nCache summary:\")\n",
    "print(f\"  crops/     : {n_crops} files\")\n",
    "print(f\"  sbi_seed42/: {n_sbi} files\")\n",
    "print(f\"  Total size : {total_size / 1e9:.2f} GB\")\n",
    "print(f\"  Location   : {CACHE_DIR}\")\n",
    "print(f\"\\nDataset sizes: train={len(train_ds)}, val={len(val_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as Kaggle Dataset\n",
    "\n",
    "After this notebook finishes:\n",
    "1. Click **\"Save Version\"** (top right) → Save & Run All → **Quick Save**\n",
    "2. Go to the notebook output → click **\"New Dataset\"**\n",
    "3. Name it: **`stf-mamba-v8-cache`**\n",
    "4. The `stf_cache/` folder with all NPZ files becomes your dataset\n",
    "\n",
    "Then in your GPU training notebook, attach `stf-mamba-v8-cache` as an input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-20T15:59:39.497386Z",
     "iopub.status.busy": "2026-02-20T15:59:39.496951Z",
     "iopub.status.idle": "2026-02-20T15:59:39.508441Z",
     "shell.execute_reply": "2026-02-20T15:59:39.506523Z",
     "shell.execute_reply.started": "2026-02-20T15:59:39.497341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Cell 7: Final verification — list what we built\n",
    "# ============================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"  Preprocessing Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  Output directory: {CACHE_DIR}\")\n",
    "print(f\"  → crops/      : {n_crops} video face crop files\")\n",
    "print(f\"  → sbi_seed42/ : {n_sbi} SBI fake cache files\")\n",
    "print(f\"  → Total size  : {total_size / 1e9:.2f} GB\")\n",
    "print(f\"\\n  Next steps:\")\n",
    "print(f\"  1. Save this notebook version\")\n",
    "print(f\"  2. Create dataset from output: 'stf-mamba-v8-cache'\")\n",
    "print(f\"  3. Open GPU notebook, attach the cache dataset\")\n",
    "print(f\"  4. Train!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
