{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":5380830,"datasetId":3120670,"databundleVersionId":5454468},{"sourceType":"datasetVersion","sourceId":10125851,"datasetId":6248577,"databundleVersionId":10408999},{"sourceType":"datasetVersion","sourceId":1320834,"datasetId":765805,"databundleVersionId":1353100},{"sourceType":"datasetVersion","sourceId":14902571,"datasetId":9535469,"databundleVersionId":15767467}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# STF-Mamba V8.0 — Kaggle Training Notebook\n\n**Semantic Temporal Forensics via Hydra-Mamba and DINOv2**\n\nTarget: CVPR/ICCV 2026\n\n**Settings:** GPU T4 x2, Internet ON\n\n**Required datasets:**\n- `stf-mamba-v8-cache` (pre-built face crops + SBI cache from preprocessing notebook)\n- `celeb-df-v2` (for cross-dataset evaluation)\n- `shape-predictor81` (dlib landmarks for Celeb-DF eval)","metadata":{}},{"cell_type":"markdown","source":"## Section 1: Setup + GPU Check + Install Dependencies","metadata":{}},{"cell_type":"code","source":"# # ============================================================================\n# # Section 1: Setup + GPU Check + Install Dependencies\n# # ============================================================================\n# import os, sys, subprocess, time\n\n# # GPU check\n# print(\"=\" * 60)\n# print(\"  STF-Mamba V8.0 — Kaggle Training\")\n# print(\"=\" * 60)\n# !nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n\n# import torch\n# print(f\"\\nPyTorch: {torch.__version__}\")\n# print(f\"CUDA: {torch.cuda.is_available()}, GPUs: {torch.cuda.device_count()}\")\n# for i in range(torch.cuda.device_count()):\n#     print(f\"  GPU {i}: {torch.cuda.get_device_name(i)} ({torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB)\")\n\n# # Install mamba_ssm — try import first, else compile\n# print(\"\\n--- Mamba SSM ---\")\n# MAMBA_OK = False\n# try:\n#     from mamba_ssm import Mamba\n#     print(f\"✓ mamba_ssm already installed\")\n#     MAMBA_OK = True\n# except ImportError:\n#     print(\"Compiling mamba_ssm from source (~20-30 min)...\")\n#     print(\"(CPU will be at 400% — this is normal)\")\n#     os.environ[\"MAX_JOBS\"] = \"2\"\n#     !pip install causal-conv1d --no-build-isolation -q 2>&1 | tail -3\n#     !pip install mamba-ssm --no-build-isolation -q 2>&1 | tail -3\n#     try:\n#         from mamba_ssm import Mamba\n#         print(f\"✓ mamba_ssm compiled successfully\")\n#         MAMBA_OK = True\n#     except:\n#         print(\"⚠ mamba_ssm failed — using Conv1d fallback\")\n\n# !pip install dlib imutils albumentations einops -q\n# print(\"\\n✓ Section 1 complete\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1.1 GPU Check\nimport os, sys, torch\nprint(\"=\" * 60)\nprint(\"  STF-Mamba V8.0 — GPU Check\")\nprint(\"=\" * 60)\n!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\nprint(f\"PyTorch: {torch.__version__} | CUDA: {torch.cuda.is_available()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1.2 Fast CUDA Kernel Build\nprint(\"Installing causal-conv1d (Fast kernels)...\")\nos.environ[\"MAX_JOBS\"] = \"2\"\n!pip install causal-conv1d --no-build-isolation -q\nprint(\"✓ causal-conv1d installed\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1.3 Heavy Mamba Compilation\nprint(\"Compiling mamba-ssm from source\")\n!pip install mamba-ssm --no-build-isolation -q\ntry:\n    from mamba_ssm import Mamba\n    print(\"✓ mamba_ssm compiled successfully\")\nexcept ImportError:\n    print(\"⚠ Error: mamba_ssm failed to compile.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1.4 CV Dependencies\nprint(\"Installing vision utilities...\")\n!pip install dlib imutils albumentations einops -q\nprint(\"\\n✓ Section 1 complete — Environment is Ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 2: Clone Repo + Path Configuration","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# Section 2: Clone Repo + Path Configuration\n# ============================================================================\nREPO_URL = \"https://github.com/AbdelRahman-Madboly/STF-Mamba_V8.0.git\"\nREPO_DIR = \"/kaggle/working/STF-Mamba_V8.0\"\n\nif not os.path.exists(REPO_DIR):\n    !git clone {REPO_URL} {REPO_DIR}\nelse:\n    print(f\"Repo already cloned at {REPO_DIR}\")\n    !cd {REPO_DIR} && git pull\n\nsys.path.insert(0, REPO_DIR)\nos.chdir(REPO_DIR)\n\nfrom stf_mamba import STFMambaV8, STFMambaLoss, is_mamba_available\nfrom data import SBIVideoDataset, get_train_transforms, get_val_transforms, load_all_splits\nfrom training import Trainer, build_optimizer, build_scheduler\n\nprint(f\"\\nRepo: {REPO_DIR}\")\nprint(f\"Mamba SSM: {'native' if is_mamba_available() else 'Conv1d fallback'}\")\nprint(\"✓ Section 2 complete — all imports OK\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 3: Dataset Paths\n\n**Key change:** Cache is loaded from pre-built dataset, NOT built on the fly.","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# Section 3: Dataset Paths — Load Pre-Built Cache\n# ============================================================================\nfrom pathlib import Path\n\nKAGGLE_INPUT = Path(\"/kaggle/input\")\n\n# --- Find pre-built cache dataset ---\nCACHE_DATASET = None\nfor p in sorted(KAGGLE_INPUT.rglob(\"crops\")):\n    if p.is_dir() and any(f.name.endswith(\"_crops.npz\") for f in p.iterdir()):\n        CACHE_DATASET = str(p.parent)  # parent of crops/\n        break\n\nif CACHE_DATASET is None:\n    # Fallback: search by dataset name\n    for name in [\"stf-mamba-v8-cache\", \"stf-cache\", \"stf_cache\"]:\n        for p in KAGGLE_INPUT.rglob(name):\n            if p.is_dir():\n                CACHE_DATASET = str(p)\n                break\n\nif CACHE_DATASET is None:\n    raise RuntimeError(\n        \"Pre-built cache not found!\\n\"\n        \"Run the preprocessing notebook first and attach 'stf-mamba-v8-cache' dataset.\"\n    )\n\n# Verify cache contents\nn_crops = len([f for f in os.listdir(os.path.join(CACHE_DATASET, \"crops\")) if f.endswith(\".npz\")])\nsbi_dir = os.path.join(CACHE_DATASET, \"sbi_seed42\")\nn_sbi = len([f for f in os.listdir(sbi_dir) if f.endswith(\".npz\")]) if os.path.isdir(sbi_dir) else 0\nprint(f\"✓ Cache found: {CACHE_DATASET}\")\nprint(f\"  crops/     : {n_crops} files\")\nprint(f\"  sbi_seed42/: {n_sbi} files\")\n\n# Cache is read-only on Kaggle input, so we symlink or copy to working dir\nCACHE_DIR = \"/kaggle/working/cache\"\nif not os.path.exists(CACHE_DIR):\n    os.symlink(CACHE_DATASET, CACHE_DIR)\n    print(f\"  Symlinked to: {CACHE_DIR}\")\n\n# FF++ video dir (needed only if SBI cache needs regeneration — shouldn't happen)\nFF_VIDEO_DIR = \"/kaggle/input/datasets/xdxd003/ff-c23/FaceForensics++_C23/original\"\n\n# Celeb-DF\nCELEB_DF_ROOT = None\nfor p in KAGGLE_INPUT.rglob(\"*\"):\n    if p.is_dir() and \"celeb\" in p.name.lower():\n        children = [c.name for c in p.iterdir() if c.is_dir()]\n        if any(\"synth\" in c.lower() for c in children):\n            CELEB_DF_ROOT = str(p)\n            break\nprint(f\"  Celeb-DF: {CELEB_DF_ROOT or 'not found (cross-dataset eval skipped)'}\")\n\n# dlib predictor (for Celeb-DF eval only)\nPREDICTOR_PATH = \"/kaggle/working/shape_predictor_81_face_landmarks.dat\"\nif not os.path.exists(PREDICTOR_PATH):\n    for p in KAGGLE_INPUT.rglob(\"shape_predictor_81_face_landmarks.dat\"):\n        os.system(f\"cp '{p}' '{PREDICTOR_PATH}'\")\n        break\n\n# Splits + checkpoint dirs\nSPLITS_DIR = os.path.join(REPO_DIR, \"splits\")\nCHECKPOINT_DIR = \"/kaggle/working/checkpoints\"\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\nsplits = load_all_splits(SPLITS_DIR)\nprint(f\"  Splits: train={len(splits['train'])}, val={len(splits['val'])}, test={len(splits['test'])}\")\nprint(\"\\n✓ Section 3 complete\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 4: Load Cached Datasets\n\n**No preprocessing needed** — everything loads from pre-built NPZ files.","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# Section 4: Load Cached Datasets (instant — no face extraction!)\n# ============================================================================\nNUM_FRAMES = 32\nIMG_SIZE = 224\n\ntrain_tf = get_train_transforms(IMG_SIZE)\nval_tf = get_val_transforms(IMG_SIZE)\n\ntrain_ds = SBIVideoDataset(\n    split_path=os.path.join(SPLITS_DIR, \"Dataset_Split_train.json\"),\n    video_dir=FF_VIDEO_DIR,\n    cache_dir=CACHE_DIR,\n    phase=\"train\",\n    num_frames=NUM_FRAMES,\n    img_size=IMG_SIZE,\n    transform=train_tf,\n    sbi_seed=42,\n    predictor_path=PREDICTOR_PATH if os.path.exists(PREDICTOR_PATH) else None,\n)\n\nval_ds = SBIVideoDataset(\n    split_path=os.path.join(SPLITS_DIR, \"Dataset_Split_val.json\"),\n    video_dir=FF_VIDEO_DIR,\n    cache_dir=CACHE_DIR,\n    phase=\"val\",\n    num_frames=NUM_FRAMES,\n    img_size=IMG_SIZE,\n    transform=val_tf,\n    sbi_seed=42,\n    predictor_path=PREDICTOR_PATH if os.path.exists(PREDICTOR_PATH) else None,\n)\n\n# Quick sanity check\nsample = train_ds[0]\nprint(f\"Sanity check:\")\nprint(f\"  frames: {sample['frames'].shape}\")\nprint(f\"  label:  {sample['label']}\")\nprint(f\"  id:     {sample['video_id']}\")\nprint(f\"\\nDataset sizes: train={len(train_ds)}, val={len(val_ds)}\")\nprint(\"\\n✓ Section 4 complete — loaded from cache (no preprocessing needed)\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 5: Model Init + Param Count + Forward Pass Verify","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# Section 5: Model Init + Param Count + Forward Pass Verify\n# ============================================================================\nimport torch\nimport torch.nn as nn\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Device: {device}\")\n\n# Build model — use default d_conv from config\nprint(\"\\nLoading DINOv2-ViT-B/14...\")\nmodel = STFMambaV8(pretrained_backbone=True)\n\n# Param count\ntotal = sum(p.numel() for p in model.parameters())\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"\\nParameters:\")\nprint(f\"  Total:     {total / 1e6:.1f}M\")\nprint(f\"  Trainable: {trainable / 1e6:.1f}M\")\nprint(f\"  Frozen:    {(total - trainable) / 1e6:.1f}M\")\n\n# Forward pass verify\nprint(f\"\\nForward pass test...\")\nmodel.eval()\nmodel = model.to(device)\nx_test = torch.randn(1, 32, 3, 224, 224).to(device)\nwith torch.no_grad():\n    out = model(x_test)\nprint(f\"  Logits:   {out['logits'].shape}  ← expected (1, 2)\")\nprint(f\"  Variance: {out['variance'].shape} ← expected (1, 1)\")\nassert out['logits'].shape == (1, 2)\nassert out['variance'].shape == (1, 1)\n\ndel x_test, out\ntorch.cuda.empty_cache()\nmodel = model.cpu()\nprint(\"\\n✓ Section 5 complete\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 6: Training (25 Epochs)\n\nConfig: `v8_kaggle.yaml` — batch=8, 32 frames, differential LR, cosine schedule","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# Section 6: Training Loop\n# ============================================================================\nimport numpy as np\nimport random\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\n\n# Config\nconfig = {\n    \"epochs\": 25,\n    \"batch_size\": 8,\n    \"lr_backbone\": 5e-6,\n    \"lr_temporal\": 1e-4,\n    \"lr_head\": 1e-4,\n    \"weight_decay\": 1e-4,\n    \"warmup_epochs\": 3,\n    \"grad_clip\": 1.0,\n    \"lambda_var\": 0.1,\n    \"label_smoothing\": 0.0,  # CRITICAL: Bug #1 — never > 0 for K=2\n}\n\ntrain_loader = torch.utils.data.DataLoader(\n    train_ds, batch_size=config[\"batch_size\"], shuffle=True,\n    num_workers=0, collate_fn=SBIVideoDataset.collate_fn,\n    pin_memory=True, drop_last=True,\n)\nval_loader = torch.utils.data.DataLoader(\n    val_ds, batch_size=config[\"batch_size\"], shuffle=False,\n    num_workers=0, collate_fn=SBIVideoDataset.collate_fn,\n    pin_memory=True,\n)\n\ncriterion = STFMambaLoss(lambda_var=config[\"lambda_var\"])\nmodel = STFMambaV8(pretrained_backbone=True)\n\ntrainer = Trainer(\n    model=model, criterion=criterion,\n    train_loader=train_loader, val_loader=val_loader,\n    config=config, save_dir=CHECKPOINT_DIR, device=device,\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(f\"  Starting STF-Mamba V8.0 Training: {config['epochs']} Epochs\")\nprint(\"=\" * 60)\n\nhistory = trainer.train(num_epochs=config[\"epochs\"])\nprint(f\"\\nTraining Complete! Best Val AUC: {trainer.best_val_auc:.4f}\")\nprint(\"✓ Section 6 complete\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 6b: Training Curves ---\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\nepochs = range(1, len(history['train_loss']) + 1)\n\naxes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train')\naxes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val')\naxes[0, 0].set_title('Loss'); axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(epochs, history['train_acc'], 'b-', label='Train')\naxes[0, 1].plot(epochs, history['val_acc'], 'r-', label='Val')\naxes[0, 1].set_title('Accuracy'); axes[0, 1].legend(); axes[0, 1].grid(True, alpha=0.3)\n\naxes[1, 0].plot(epochs, history['val_auc'], 'g-', marker='o', markersize=3)\naxes[1, 0].axhline(y=0.75, color='orange', linestyle='--', alpha=0.7, label='Stage 5 (0.75)')\naxes[1, 0].axhline(y=0.90, color='red', linestyle='--', alpha=0.7, label='Paper (0.90)')\naxes[1, 0].set_title('Val AUC'); axes[1, 0].set_ylim([0.4, 1.0]); axes[1, 0].legend(); axes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].plot(epochs, history['var_gap'], 'm-', marker='o', markersize=3)\naxes[1, 1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\naxes[1, 1].set_title('Variance Gap'); axes[1, 1].grid(True, alpha=0.3)\n\nfig.suptitle('STF-Mamba V8.0 — Kaggle Training (25 epochs)', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig(os.path.join(CHECKPOINT_DIR, 'training_curves.png'), dpi=150, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 7: Evaluation — FF++ Val + Celeb-DF AUC","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# Section 7a: FF++ Val AUC\n# ============================================================================\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\nbest_path = os.path.join(CHECKPOINT_DIR, \"best.pth\")\nprint(f\"Loading best checkpoint: {best_path}\")\nckpt = torch.load(best_path, map_location=device)\n\neval_model = STFMambaV8(pretrained_backbone=True).to(device)\neval_model.load_state_dict(ckpt['model_state_dict'])\neval_model.eval()\n\nall_probs, all_labels, all_variances = [], [], []\nwith torch.no_grad():\n    for batch in val_loader:\n        frames = batch['frames'].to(device)\n        labels = batch['label']\n        out = eval_model(frames)\n        probs = torch.softmax(out['logits'], dim=1)[:, 1].cpu().numpy()\n        var = out['variance'].cpu().numpy().flatten()\n        all_probs.extend(probs)\n        all_labels.extend(labels.numpy())\n        all_variances.extend(var)\n\nff_val_auc = roc_auc_score(all_labels, all_probs)\nff_val_acc = accuracy_score(all_labels, [1 if p > 0.5 else 0 for p in all_probs])\nall_labels_np = np.array(all_labels)\nall_var_np = np.array(all_variances)\nvar_real = all_var_np[all_labels_np == 0].mean()\nvar_fake = all_var_np[all_labels_np == 1].mean()\n\nprint(f\"\\nFF++ Val AUC: {ff_val_auc:.4f}\")\nprint(f\"FF++ Val Acc: {ff_val_acc:.4f}\")\nprint(f\"Variance gap: {var_fake - var_real:+.6f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# Section 7b: Celeb-DF Cross-Dataset Evaluation\n# ============================================================================\nimport cv2\nfrom data.preprocessing import FacePreprocessor\nfrom data.augmentation import apply_transform_to_clip\n\ncdf_auc = None\n\nif CELEB_DF_ROOT and os.path.isdir(CELEB_DF_ROOT):\n    print(\"--- Celeb-DF v2 Cross-Dataset ---\")\n    \n    cdf_real_dirs = [os.path.join(CELEB_DF_ROOT, d) for d in [\"Celeb-real\", \"YouTube-real\", \"celeb_real\"]]\n    cdf_fake_dirs = [os.path.join(CELEB_DF_ROOT, d) for d in [\"Celeb-synthesis\", \"celeb_synthesis\"]]\n\n    def find_videos(dir_list):\n        videos = []\n        for d in dir_list:\n            if os.path.isdir(d):\n                for f in sorted(os.listdir(d)):\n                    if f.lower().endswith(('.mp4', '.avi')):\n                        videos.append(os.path.join(d, f))\n        return videos\n\n    cdf_real = find_videos(cdf_real_dirs)\n    cdf_fake = find_videos(cdf_fake_dirs)\n    print(f\"  Real: {len(cdf_real)}, Fake: {len(cdf_fake)}\")\n\n    if cdf_real and cdf_fake:\n        from tqdm import tqdm\n        cdf_preprocessor = FacePreprocessor(\n            video_dir=CELEB_DF_ROOT,\n            cache_dir=\"/kaggle/working/cdf_cache\",\n            num_frames=NUM_FRAMES, img_size=IMG_SIZE,\n            predictor_path=PREDICTOR_PATH if os.path.exists(PREDICTOR_PATH) else None,\n        )\n\n        def eval_videos(video_paths, label):\n            probs = []\n            for vpath in tqdm(video_paths[:200], desc=f\"label={label}\"):\n                vid_id = os.path.splitext(os.path.basename(vpath))[0]\n                try:\n                    crops, _ = cdf_preprocessor.get_video(vid_id)\n                    frames_t = apply_transform_to_clip(crops[:NUM_FRAMES], val_tf)\n                    frames_t = frames_t.unsqueeze(0).to(device)\n                    with torch.no_grad():\n                        out = eval_model(frames_t)\n                        prob = torch.softmax(out['logits'], dim=1)[0, 1].item()\n                    probs.append(prob)\n                except:\n                    continue\n            return probs\n\n        real_probs = eval_videos(cdf_real, 0)\n        fake_probs = eval_videos(cdf_fake, 1)\n        \n        if real_probs and fake_probs:\n            cdf_labels = [0]*len(real_probs) + [1]*len(fake_probs)\n            cdf_probs = real_probs + fake_probs\n            cdf_auc = roc_auc_score(cdf_labels, cdf_probs)\n            print(f\"\\n  Celeb-DF AUC: {cdf_auc:.4f}\")\nelse:\n    print(\"Celeb-DF not found — skipping\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# Section 7c: Results Summary\n# ============================================================================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"  RESULTS SUMMARY — STF-Mamba V8.0 (Kaggle 25 epochs)\")\nprint(\"=\" * 60)\nprint(f\"\\n{'Metric':<30} {'Value':>10}\")\nprint(\"-\" * 42)\nprint(f\"{'FF++ Val AUC (SBI)':<30} {ff_val_auc:>10.4f}\")\nprint(f\"{'FF++ Val Acc':<30} {ff_val_acc:>10.4f}\")\nif cdf_auc: print(f\"{'Celeb-DF AUC':<30} {cdf_auc:>10.4f}\")\nprint(f\"{'Variance gap (fake-real)':<30} {var_fake - var_real:>+10.6f}\")\nprint(f\"{'Best epoch':<30} {ckpt['epoch']:>10d}\")\n\nprint(f\"\\n--- Comparison to Baselines ---\")\nprint(f\"{'Model':<35} {'FF++ Val':>10} {'CDF':>10}\")\nprint(\"-\" * 57)\nprint(f\"{'B0 frame-level (Step 3)':<35} {'0.6850':>10} {'0.6135':>10}\")\nprint(f\"{'B0 + GRU temporal (Step 4)':<35} {'0.5954':>10} {'0.5524':>10}\")\nprint(f\"{'SBI reference (EffNet-B4)':<35} {'—':>10} {'0.9382':>10}\")\ncdf_str = f\"{cdf_auc:.4f}\" if cdf_auc else \"—\"\nprint(f\"{'V8.0 (this run)':<35} {ff_val_auc:>10.4f} {cdf_str:>10}\")\n\nprint(f\"\\n--- Stage 5 Exit Criteria ---\")\nif cdf_auc and cdf_auc > 0.75: print(f\"  ✓ CDF AUC {cdf_auc:.4f} > 0.75\")\nelif cdf_auc: print(f\"  ✗ CDF AUC {cdf_auc:.4f} < 0.75\")\nelse: print(f\"  ? CDF AUC not measured\")\nif var_fake - var_real > 0: print(f\"  ✓ Variance gap positive ({var_fake-var_real:+.6f})\")\nelse: print(f\"  ✗ Variance gap not positive\")\nlast5 = history['val_loss'][-5:]\nif len(last5) >= 5 and last5[-1] <= last5[0] * 1.2: print(f\"  ✓ No overfitting\")\nprint(\"\\n✓ Section 7 complete\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Section 8: Variance Visualization","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# Section 8: Variance Visualization\n# ============================================================================\nimport matplotlib.pyplot as plt\n\nn_samples = min(10, len(val_ds) // 2)\nreal_sims, fake_sims = [], []\nreal_vars, fake_vars = [], []\n\neval_model.eval()\nwith torch.no_grad():\n    for i in range(min(n_samples * 2, len(val_ds))):\n        sample = val_ds[i]\n        frames = sample['frames'].unsqueeze(0).to(device)\n        out = eval_model(frames)\n        sims = out['similarities'][0].cpu().numpy()\n        var = out['variance'][0].item()\n        if sample['label'] == 0:\n            real_sims.append(sims); real_vars.append(var)\n        else:\n            fake_sims.append(sims); fake_vars.append(var)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 5))\nfor i, s in enumerate(real_sims[:5]):\n    axes[0].plot(s, alpha=0.6, label=f'Real {i}')\naxes[0].set_title(f'Real — Mean σ²={np.mean(real_vars):.6f}')\naxes[0].set_ylim([0.5, 1.05]); axes[0].legend(fontsize=8); axes[0].grid(True, alpha=0.3)\n\nfor i, s in enumerate(fake_sims[:5]):\n    axes[1].plot(s, alpha=0.6, label=f'Fake {i}')\naxes[1].set_title(f'Fake — Mean σ²={np.mean(fake_vars):.6f}')\naxes[1].set_ylim([0.5, 1.05]); axes[1].legend(fontsize=8); axes[1].grid(True, alpha=0.3)\n\nfig.suptitle('STF-Mamba V8.0 — Identity Consistency Signal', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig(os.path.join(CHECKPOINT_DIR, 'similarity_traces.png'), dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\nVariance Statistics:\")\nprint(f\"  Real: {np.mean(real_vars):.6f} ± {np.std(real_vars):.6f}\")\nprint(f\"  Fake: {np.mean(fake_vars):.6f} ± {np.std(fake_vars):.6f}\")\nprint(f\"  Gap:  {np.mean(fake_vars) - np.mean(real_vars):+.6f}\")\n\nprint(\"\\n✓ Section 8 complete\")\nprint(\"\\n\" + \"=\" * 60)\nprint(\"  STF-Mamba V8.0 — Training Complete\")\nprint(\"=\" * 60)\nprint(f\"  Best FF++ Val AUC: {ff_val_auc:.4f}\")\nif cdf_auc: print(f\"  Celeb-DF AUC: {cdf_auc:.4f}\")\nprint(f\"  Next: Stage 6 — RunPod A100 full 50-epoch training\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}