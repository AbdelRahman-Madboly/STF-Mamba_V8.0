{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd69b62f-3368-41a6-85ad-58307dfa04c2",
   "metadata": {},
   "source": [
    "# üî¨ Step 1: Semantic Signal Proof\n",
    "## Testing Content-Level Signals That Survive CRF23 Compression\n",
    "\n",
    "**Previous finding:** Pixel-level noise signals (HLL, gradient sharpness, autocorrelation) ‚Üí all failed.  \n",
    "**Root cause:** H.264 CRF23 compression homogenizes the noise floor across real and fake equally.\n",
    "\n",
    "**New hypothesis:** The signal is in the *content*, not the noise.  \n",
    "Signals that live in low-frequency content survive compression.\n",
    "\n",
    "### Two Tests This Session\n",
    "\n",
    "| Test | Signal | Method | Needs Pretrained? |\n",
    "|------|--------|--------|-------------------|\n",
    "| A | Color statistics inconsistency (face vs background) | Wasserstein distance on histograms | ‚ùå No |\n",
    "| B | Optical flow boundary inconsistency | OpenCV Farneback flow | ‚ùå No |\n",
    "\n",
    "### Go/No-Go\n",
    "- **Either test separates real/fake with p < 0.05** ‚Üí we have a content-level anchor ‚Üí add to V8.0 on top of pretrained backbone\n",
    "- **Both fail** ‚Üí signal requires pretrained semantic features ‚Üí skip straight to baseline training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b334ad-42d5-44ae-b799-2be5f4ef9a6c",
   "metadata": {},
   "source": [
    "## Section 1 ‚Äî Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5897f220-5542-47dd-b82f-63bde5684d5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:35:35.268206Z",
     "iopub.status.busy": "2026-02-18T23:35:35.267991Z",
     "iopub.status.idle": "2026-02-18T23:35:37.973376Z",
     "shell.execute_reply": "2026-02-18T23:35:37.972730Z",
     "shell.execute_reply.started": "2026-02-18T23:35:35.268184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, json, random, warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "from scipy.stats import wasserstein_distance\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "OUTPUT_DIR = Path('/kaggle/working/semantic_signal')\n",
    "PLOTS_DIR  = OUTPUT_DIR / 'plots'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "N_SAMPLE  = 25    # more samples this time for better statistics\n",
    "N_FRAMES  = 32\n",
    "FACE_SIZE = 224   # larger crop for better color/flow measurement\n",
    "\n",
    "print(f\"NumPy {np.__version__}, OpenCV {cv2.__version__}\")\n",
    "print(f\"Outputs ‚Üí {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cce09d-2aa8-4a98-8de4-0c2ad368ffd6",
   "metadata": {},
   "source": [
    "## Section 2 ‚Äî Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc1722-a40a-4303-af77-146ccb5037ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:35:37.975025Z",
     "iopub.status.busy": "2026-02-18T23:35:37.974718Z",
     "iopub.status.idle": "2026-02-18T23:36:05.379005Z",
     "shell.execute_reply": "2026-02-18T23:36:05.378355Z",
     "shell.execute_reply.started": "2026-02-18T23:35:37.975003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "KAGGLE_INPUT = Path('/kaggle/input')\n",
    "\n",
    "def locate_ff_root(base):\n",
    "    known = base / 'datasets' / 'xdxd003' / 'ff-c23' / 'FaceForensics++_C23'\n",
    "    if known.exists():\n",
    "        return known\n",
    "    for d in sorted(base.rglob('*')):\n",
    "        if d.is_dir():\n",
    "            hits = sum(1 for m in ['Deepfakes','Face2Face','FaceSwap','NeuralTextures']\n",
    "                       if (d / m).exists())\n",
    "            if hits >= 2:\n",
    "                return d\n",
    "    return None\n",
    "\n",
    "def locate_celeb_root(base):\n",
    "    known = base / 'datasets' / 'reubensuju' / 'celeb-df-v2'\n",
    "    if known.exists():\n",
    "        return known\n",
    "    for d in sorted(base.rglob('*')):\n",
    "        if d.is_dir() and (d/'Celeb-real').exists() and (d/'Celeb-synthesis').exists():\n",
    "            return d\n",
    "    return None\n",
    "\n",
    "FF_ROOT    = locate_ff_root(KAGGLE_INPUT)\n",
    "CELEB_ROOT = locate_celeb_root(KAGGLE_INPUT)\n",
    "print(f\"FF++    : {FF_ROOT}\")\n",
    "print(f\"Celeb-DF: {CELEB_ROOT}\")\n",
    "\n",
    "FF_METHODS = ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']\n",
    "FF_VIDEOS  = {}\n",
    "CELEB_VIDEOS = {}\n",
    "\n",
    "if FF_ROOT:\n",
    "    real = list(FF_ROOT.rglob('original*/*.mp4'))\n",
    "    if not real:\n",
    "        real = [p for p in FF_ROOT.rglob('*.mp4') if 'original' in str(p).lower()]\n",
    "    FF_VIDEOS['real'] = sorted(real)\n",
    "    for m in FF_METHODS:\n",
    "        paths = list((FF_ROOT / m).glob('*.mp4')) if (FF_ROOT / m).exists() else []\n",
    "        if paths:\n",
    "            FF_VIDEOS[m] = sorted(paths)\n",
    "    for k, v in FF_VIDEOS.items():\n",
    "        print(f\"  FF++/{k:20s}: {len(v):4d} videos\")\n",
    "\n",
    "if CELEB_ROOT:\n",
    "    CELEB_VIDEOS['real'] = (list((CELEB_ROOT/'Celeb-real').glob('*.mp4')) +\n",
    "                            list((CELEB_ROOT/'YouTube-real').glob('*.mp4')))\n",
    "    CELEB_VIDEOS['fake'] = list((CELEB_ROOT/'Celeb-synthesis').glob('*.mp4'))\n",
    "    for k, v in CELEB_VIDEOS.items():\n",
    "        print(f\"  Celeb-DF/{k:10s}: {len(v):4d} videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c1a441-e747-48e0-a9a6-c6c342df8af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:36:05.380222Z",
     "iopub.status.busy": "2026-02-18T23:36:05.379896Z",
     "iopub.status.idle": "2026-02-18T23:36:08.675239Z",
     "shell.execute_reply": "2026-02-18T23:36:08.674616Z",
     "shell.execute_reply.started": "2026-02-18T23:36:05.380192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path: str, n_frames: int = N_FRAMES,\n",
    "                   size: int = FACE_SIZE) -> Optional[np.ndarray]:\n",
    "    \"\"\"Extract n evenly-spaced frames. Returns (T, H, W, 3) uint8 or None.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total < n_frames:\n",
    "        cap.release()\n",
    "        return None\n",
    "    indices = np.linspace(0, total - 1, n_frames, dtype=int)\n",
    "    frames  = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Keep full frame ‚Äî we need face AND background for color comparison\n",
    "        frame = cv2.resize(frame, (size, size))\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    if len(frames) < n_frames // 2:\n",
    "        return None\n",
    "    while len(frames) < n_frames:\n",
    "        frames.append(frames[-1])\n",
    "    return np.stack(frames[:n_frames], axis=0)\n",
    "\n",
    "def sample(lst, n=N_SAMPLE, seed=SEED):\n",
    "    rng = random.Random(seed)\n",
    "    return rng.sample(lst, min(n, len(lst)))\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Define face and background regions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Face: center 50% of the frame (where the swapped face lives)\n",
    "# Background: outer ring (where the original video content remains)\n",
    "# This split is the key to color inconsistency detection\n",
    "\n",
    "def get_regions(H, W):\n",
    "    \"\"\"Return slice objects for face center and background border.\"\"\"\n",
    "    cy1, cy2 = H // 4, 3 * H // 4\n",
    "    cx1, cx2 = W // 4, 3 * W // 4\n",
    "    return (cy1, cy2, cx1, cx2)   # face region coords\n",
    "\n",
    "# Test\n",
    "frames = extract_frames(str(FF_VIDEOS['real'][0])) if FF_VIDEOS.get('real') else None\n",
    "if frames is not None:\n",
    "    H, W = frames.shape[1], frames.shape[2]\n",
    "    cy1, cy2, cx1, cx2 = get_regions(H, W)\n",
    "    print(f\"‚úÖ Loader OK ‚Äî frames: {frames.shape}\")\n",
    "    print(f\"   Face region:       [{cy1}:{cy2}, {cx1}:{cx2}]  \"\n",
    "          f\"({cy2-cy1}√ó{cx2-cx1} px)\")\n",
    "    print(f\"   Background region: outer ring\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Loader failed ‚Äî check dataset path\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189cbeae-9b7b-4fa8-96ab-94e17a190b60",
   "metadata": {},
   "source": [
    "## Section 3 ‚Äî Test A: Color Statistics Inconsistency\n",
    "\n",
    "### The Hypothesis\n",
    "In a deepfake, the swapped face region comes from a different video (different camera,\n",
    "different lighting session, different color grading) than the background.\n",
    "\n",
    "Even after compression, the **color distribution** of the face center vs the background\n",
    "should be more inconsistent in fakes than in real videos.\n",
    "\n",
    "**Metric:** Wasserstein distance between the color histogram of the face region  \n",
    "and the color histogram of the background region, averaged across all frames.\n",
    "\n",
    "- Real video: face and background have similar color stats (same camera, same scene)  \n",
    "- Deepfake: face has different color stats (different source video)\n",
    "\n",
    "We also measure **temporal consistency** of this ratio ‚Äî in fakes it should be stable\n",
    "(persistent color mismatch) while in real videos it should fluctuate naturally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4ca6f-d795-48af-8829-9e0ea716ddb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:36:08.677197Z",
     "iopub.status.busy": "2026-02-18T23:36:08.676960Z",
     "iopub.status.idle": "2026-02-18T23:36:08.750586Z",
     "shell.execute_reply": "2026-02-18T23:36:08.749965Z",
     "shell.execute_reply.started": "2026-02-18T23:36:08.677176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def color_inconsistency(frames_rgb: np.ndarray, n_bins: int = 32) -> Dict:\n",
    "    \"\"\"\n",
    "    Measure color histogram distance between face center and background.\n",
    "    \n",
    "    Returns:\n",
    "        wasserstein_mean: mean W-distance across frames and channels\n",
    "        wasserstein_std:  std across frames (low = persistent mismatch)\n",
    "        per_frame_wdist:  list of per-frame distances\n",
    "        ratio_temporal_std: how much the face/bg ratio changes over time\n",
    "    \"\"\"\n",
    "    T, H, W, C = frames_rgb.shape\n",
    "    cy1, cy2, cx1, cx2 = get_regions(H, W)\n",
    "\n",
    "    per_frame = []\n",
    "\n",
    "    for t in range(T):\n",
    "        frame = frames_rgb[t].astype(np.float32) / 255.0\n",
    "\n",
    "        # Extract regions\n",
    "        face_region = frame[cy1:cy2, cx1:cx2]           # center\n",
    "\n",
    "        # Background: combine top, bottom, left, right strips\n",
    "        bg_top    = frame[:cy1, :]\n",
    "        bg_bottom = frame[cy2:, :]\n",
    "        bg_left   = frame[cy1:cy2, :cx1]\n",
    "        bg_right  = frame[cy1:cy2, cx2:]\n",
    "        background = np.concatenate([\n",
    "            bg_top.reshape(-1, C),\n",
    "            bg_bottom.reshape(-1, C),\n",
    "            bg_left.reshape(-1, C),\n",
    "            bg_right.reshape(-1, C)\n",
    "        ], axis=0)\n",
    "\n",
    "        face_flat = face_region.reshape(-1, C)\n",
    "\n",
    "        # Wasserstein distance per channel, then average\n",
    "        channel_dists = []\n",
    "        for c in range(C):\n",
    "            # Histogram-based: bin both distributions\n",
    "            bins  = np.linspace(0, 1, n_bins + 1)\n",
    "            face_hist, _ = np.histogram(face_flat[:, c], bins=bins, density=True)\n",
    "            bg_hist,   _ = np.histogram(background[:, c], bins=bins, density=True)\n",
    "            # Normalize to probability\n",
    "            face_hist = face_hist / (face_hist.sum() + 1e-8)\n",
    "            bg_hist   = bg_hist   / (bg_hist.sum()   + 1e-8)\n",
    "            wd = wasserstein_distance(face_hist, bg_hist)\n",
    "            channel_dists.append(wd)\n",
    "\n",
    "        per_frame.append(float(np.mean(channel_dists)))\n",
    "\n",
    "    per_frame = np.array(per_frame)\n",
    "\n",
    "    return {\n",
    "        'wdist_mean':      float(per_frame.mean()),\n",
    "        'wdist_median':    float(np.median(per_frame)),\n",
    "        'wdist_std':       float(per_frame.std()),\n",
    "        # Temporal consistency: low std = persistent mismatch = fake signal\n",
    "        'temporal_consistency': float(1.0 / (per_frame.std() + 1e-8)),\n",
    "        'per_frame':       per_frame.tolist(),\n",
    "    }\n",
    "\n",
    "# Quick test\n",
    "if frames is not None:\n",
    "    result = color_inconsistency(frames)\n",
    "    print(f\"‚úÖ color_inconsistency test:\")\n",
    "    print(f\"   wdist_mean={result['wdist_mean']:.5f}\")\n",
    "    print(f\"   wdist_std ={result['wdist_std']:.5f}\")\n",
    "    print(f\"   temporal_consistency={result['temporal_consistency']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b2ec9-b9f2-46bb-b5b7-0d7bfab086f2",
   "metadata": {},
   "source": [
    "## Section 4 ‚Äî Test B: Optical Flow Boundary Inconsistency\n",
    "\n",
    "### The Hypothesis\n",
    "In a real video, the face moves coherently with the scene ‚Äî the optical flow vectors\n",
    "at the face boundary are smooth and continuous.\n",
    "\n",
    "In a deepfake, the generated face has slightly different motion than the background it's\n",
    "composited into. The flow vectors at the **face boundary** should be more discontinuous\n",
    "in fakes than in real videos.\n",
    "\n",
    "**Metric:** Mean flow magnitude discontinuity at the face boundary  \n",
    "(difference between flow inside face region vs flow just outside it).\n",
    "\n",
    "This signal survives compression because optical flow operates on content,\n",
    "not on pixel-level noise statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0e4e9-f49f-46be-92b4-05f9fe595554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:36:08.751484Z",
     "iopub.status.busy": "2026-02-18T23:36:08.751252Z",
     "iopub.status.idle": "2026-02-18T23:36:09.264908Z",
     "shell.execute_reply": "2026-02-18T23:36:09.264286Z",
     "shell.execute_reply.started": "2026-02-18T23:36:08.751460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def optical_flow_inconsistency(frames_rgb: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Measure optical flow discontinuity at the face/background boundary.\n",
    "    \n",
    "    Returns:\n",
    "        boundary_discontinuity_mean: mean flow magnitude difference at boundary\n",
    "        interior_flow_mean: mean flow magnitude inside face region  \n",
    "        exterior_flow_mean: mean flow magnitude in background\n",
    "        flow_ratio: interior/exterior flow ratio\n",
    "        per_frame: per consecutive-frame-pair measurements\n",
    "    \"\"\"\n",
    "    T, H, W, C = frames_rgb.shape\n",
    "    cy1, cy2, cx1, cx2 = get_regions(H, W)\n",
    "\n",
    "    # Convert to grayscale for optical flow\n",
    "    gray_frames = [cv2.cvtColor(f, cv2.COLOR_RGB2GRAY) for f in frames_rgb]\n",
    "\n",
    "    # Boundary mask: thin ring (8px) around the face region\n",
    "    boundary_mask = np.zeros((H, W), dtype=bool)\n",
    "    ring = 8\n",
    "    # Inner edge of face region\n",
    "    boundary_mask[cy1:cy1+ring, cx1:cx2] = True   # top edge\n",
    "    boundary_mask[cy2-ring:cy2, cx1:cx2] = True   # bottom edge\n",
    "    boundary_mask[cy1:cy2, cx1:cx1+ring] = True   # left edge\n",
    "    boundary_mask[cy1:cy2, cx2-ring:cx2] = True   # right edge\n",
    "\n",
    "    # Face interior (excluding boundary)\n",
    "    face_mask = np.zeros((H, W), dtype=bool)\n",
    "    face_mask[cy1+ring:cy2-ring, cx1+ring:cx2-ring] = True\n",
    "\n",
    "    # Background mask\n",
    "    bg_mask = np.zeros((H, W), dtype=bool)\n",
    "    bg_mask[:cy1, :]  = True\n",
    "    bg_mask[cy2:, :]  = True\n",
    "    bg_mask[:, :cx1]  = True\n",
    "    bg_mask[:, cx2:]  = True\n",
    "\n",
    "    per_frame_boundary = []\n",
    "    per_frame_interior = []\n",
    "    per_frame_exterior = []\n",
    "\n",
    "    for t in range(T - 1):\n",
    "        f1 = gray_frames[t]\n",
    "        f2 = gray_frames[t + 1]\n",
    "\n",
    "        # Farneback optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            f1, f2, None,\n",
    "            pyr_scale=0.5, levels=3, winsize=15,\n",
    "            iterations=3, poly_n=5, poly_sigma=1.2,\n",
    "            flags=0\n",
    "        )  # flow: (H, W, 2)\n",
    "\n",
    "        mag = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)   # (H, W)\n",
    "\n",
    "        boundary_mag = mag[boundary_mask].mean() if boundary_mask.any() else 0.0\n",
    "        interior_mag = mag[face_mask].mean()     if face_mask.any()     else 0.0\n",
    "        exterior_mag = mag[bg_mask].mean()       if bg_mask.any()       else 0.0\n",
    "\n",
    "        per_frame_boundary.append(float(boundary_mag))\n",
    "        per_frame_interior.append(float(interior_mag))\n",
    "        per_frame_exterior.append(float(exterior_mag))\n",
    "\n",
    "    interior = np.array(per_frame_interior)\n",
    "    exterior = np.array(per_frame_exterior)\n",
    "    boundary = np.array(per_frame_boundary)\n",
    "\n",
    "    # Key metric: how different is the flow at the boundary vs interior?\n",
    "    # High discontinuity = face and background moving differently = fake\n",
    "    boundary_vs_interior = np.abs(boundary - interior)\n",
    "    flow_ratio = interior / (exterior + 1e-8)   # >1 = face moves more than bg\n",
    "\n",
    "    return {\n",
    "        'boundary_discontinuity_mean': float(boundary_vs_interior.mean()),\n",
    "        'boundary_discontinuity_std':  float(boundary_vs_interior.std()),\n",
    "        'interior_flow_mean':          float(interior.mean()),\n",
    "        'exterior_flow_mean':          float(exterior.mean()),\n",
    "        'flow_ratio_mean':             float(flow_ratio.mean()),\n",
    "        'flow_ratio_std':              float(flow_ratio.std()),\n",
    "        'per_frame_interior':          interior.tolist(),\n",
    "        'per_frame_exterior':          exterior.tolist(),\n",
    "        'per_frame_boundary_disc':     boundary_vs_interior.tolist(),\n",
    "    }\n",
    "\n",
    "# Quick test\n",
    "if frames is not None:\n",
    "    result = optical_flow_inconsistency(frames)\n",
    "    print(f\"‚úÖ optical_flow_inconsistency test:\")\n",
    "    print(f\"   boundary_discontinuity={result['boundary_discontinuity_mean']:.5f}\")\n",
    "    print(f\"   flow_ratio={result['flow_ratio_mean']:.4f}\")\n",
    "    print(f\"   interior={result['interior_flow_mean']:.5f}, \"\n",
    "          f\"exterior={result['exterior_flow_mean']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e2f640-0999-4363-a099-06b4c48fa6c1",
   "metadata": {},
   "source": [
    "## Section 5 ‚Äî Run on FF++ c23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738bded-93af-49f3-81a1-7fab4b3cd5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:36:09.266105Z",
     "iopub.status.busy": "2026-02-18T23:36:09.265829Z",
     "iopub.status.idle": "2026-02-18T23:51:23.101967Z",
     "shell.execute_reply": "2026-02-18T23:51:23.101175Z",
     "shell.execute_reply.started": "2026-02-18T23:36:09.266083Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "COLORS = {\n",
    "    'real':           '#2ecc71',\n",
    "    'Deepfakes':      '#e74c3c',\n",
    "    'Face2Face':      '#e67e22',\n",
    "    'FaceSwap':       '#9b59b6',\n",
    "    'NeuralTextures': '#3498db',\n",
    "}\n",
    "\n",
    "def analyze_class(video_paths, label, n=N_SAMPLE, verbose=True):\n",
    "    results = []\n",
    "    sampled = sample(video_paths, n)\n",
    "\n",
    "    for i, vpath in enumerate(sampled):\n",
    "        frames = extract_frames(str(vpath))\n",
    "        if frames is None:\n",
    "            continue\n",
    "\n",
    "        color = color_inconsistency(frames)\n",
    "        flow  = optical_flow_inconsistency(frames)\n",
    "\n",
    "        results.append({\n",
    "            'label':  label,\n",
    "            'video':  Path(vpath).name,\n",
    "            # Test A\n",
    "            'wdist_mean':              color['wdist_mean'],\n",
    "            'wdist_std':               color['wdist_std'],\n",
    "            'temporal_consistency':    color['temporal_consistency'],\n",
    "            'per_frame_wdist':         color['per_frame'],\n",
    "            # Test B\n",
    "            'boundary_disc':           flow['boundary_discontinuity_mean'],\n",
    "            'flow_ratio':              flow['flow_ratio_mean'],\n",
    "            'flow_ratio_std':          flow['flow_ratio_std'],\n",
    "            'interior_flow':           flow['interior_flow_mean'],\n",
    "            'exterior_flow':           flow['exterior_flow_mean'],\n",
    "            'per_frame_boundary_disc': flow['per_frame_boundary_disc'],\n",
    "        })\n",
    "\n",
    "        if verbose and (i + 1) % 5 == 0:\n",
    "            r = results[-1]\n",
    "            print(f\"  [{label:15s}] {i+1:2d}/{n} | \"\n",
    "                  f\"wdist={r['wdist_mean']:.5f} | \"\n",
    "                  f\"flow_disc={r['boundary_disc']:.5f} | \"\n",
    "                  f\"flow_ratio={r['flow_ratio']:.4f}\")\n",
    "    return results\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RUNNING SEMANTIC SIGNAL TESTS ON FF++ c23\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "FF_RESULTS = {}\n",
    "run_order  = ['real'] + [m for m in FF_METHODS if m in FF_VIDEOS]\n",
    "\n",
    "for label in run_order:\n",
    "    print(f\"\\n[{label}]\")\n",
    "    FF_RESULTS[label] = analyze_class(FF_VIDEOS[label], label)\n",
    "    print(f\"  ‚Üí {len(FF_RESULTS[label])} videos done\")\n",
    "\n",
    "print(\"\\n‚úÖ FF++ analysis complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d6857-233f-477b-bb71-8f8f2dd4a36c",
   "metadata": {},
   "source": [
    "## Section 6 ‚Äî Results & Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48c139d-84e9-4ddf-a2ca-38bd3766db12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:51:23.103266Z",
     "iopub.status.busy": "2026-02-18T23:51:23.102972Z",
     "iopub.status.idle": "2026-02-18T23:51:24.187065Z",
     "shell.execute_reply": "2026-02-18T23:51:24.186375Z",
     "shell.execute_reply.started": "2026-02-18T23:51:23.103232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_metric(rd, key):\n",
    "    return {k: [r[key] for r in v] for k, v in rd.items()}\n",
    "\n",
    "def boxplot_row(ax, data_dict, title, ylabel, colors=COLORS):\n",
    "    \"\"\"Plot a single boxplot panel.\"\"\"\n",
    "    groups = list(data_dict.keys())\n",
    "    data   = [data_dict[k] for k in groups]\n",
    "    cols   = [colors.get(k, '#95a5a6') for k in groups]\n",
    "    bp = ax.boxplot(data, patch_artist=True,\n",
    "                    medianprops=dict(color='black', linewidth=2.5))\n",
    "    for patch, c in zip(bp['boxes'], cols):\n",
    "        patch.set_facecolor(c); patch.set_alpha(0.75)\n",
    "    ax.set_xticklabels([g.replace('NeuralTextures','NeuralTex.') for g in groups],\n",
    "                       rotation=30, ha='right')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    for i, (g, vals) in enumerate(zip(groups, data)):\n",
    "        med = np.median(vals)\n",
    "        ax.text(i+1, med, f'{med:.4f}', ha='center', va='bottom',\n",
    "                fontsize=8, fontweight='bold')\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ Figure 1: Test A ‚Äî Color inconsistency ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Test A: Color Statistics Inconsistency (Face vs Background)\\n'\n",
    "             'Higher Wasserstein distance = more color mismatch = fake?',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "for ax, key, title, ylabel in zip(\n",
    "    axes,\n",
    "    ['wdist_mean', 'wdist_std', 'temporal_consistency'],\n",
    "    ['W-Distance (mean)', 'W-Distance (std across frames)', 'Temporal Consistency (1/std)'],\n",
    "    ['Wasserstein distance', 'Std', '1/std (higher = more stable)']\n",
    "):\n",
    "    boxplot_row(ax, get_metric(FF_RESULTS, key), title, ylabel)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'test_a_color.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ test_a_color.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199f5e08-b489-48a6-8b38-703504e9cbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:51:24.188302Z",
     "iopub.status.busy": "2026-02-18T23:51:24.187947Z",
     "iopub.status.idle": "2026-02-18T23:51:25.073298Z",
     "shell.execute_reply": "2026-02-18T23:51:25.072832Z",
     "shell.execute_reply.started": "2026-02-18T23:51:24.188276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Figure 2: Test B ‚Äî Optical flow ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Test B: Optical Flow Boundary Inconsistency\\n'\n",
    "             'Higher discontinuity at face boundary = face moving differently from background?',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "for ax, key, title, ylabel in zip(\n",
    "    axes,\n",
    "    ['boundary_disc', 'flow_ratio', 'flow_ratio_std'],\n",
    "    ['Boundary Discontinuity', 'Flow Ratio (interior/exterior)', 'Flow Ratio Std'],\n",
    "    ['|boundary - interior| flow', 'Ratio', 'Std across frames']\n",
    "):\n",
    "    boxplot_row(ax, get_metric(FF_RESULTS, key), title, ylabel)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'test_b_flow.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ test_b_flow.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55771bbc-d035-4648-ae1b-e11389f24fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:51:25.074599Z",
     "iopub.status.busy": "2026-02-18T23:51:25.074347Z",
     "iopub.status.idle": "2026-02-18T23:51:25.102032Z",
     "shell.execute_reply": "2026-02-18T23:51:25.101364Z",
     "shell.execute_reply.started": "2026-02-18T23:51:25.074579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Statistics table ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STATISTICAL RESULTS ‚Äî FF++ c23\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "metrics = [\n",
    "    ('wdist_mean',           'Test A ‚Äî W-Distance Mean'),\n",
    "    ('temporal_consistency', 'Test A ‚Äî Temporal Consistency'),\n",
    "    ('boundary_disc',        'Test B ‚Äî Boundary Discontinuity'),\n",
    "    ('flow_ratio',           'Test B ‚Äî Flow Ratio (interior/exterior)'),\n",
    "]\n",
    "\n",
    "for metric_key, metric_name in metrics:\n",
    "    real_vals = [r[metric_key] for r in FF_RESULTS.get('real', [])]\n",
    "    real_med  = np.median(real_vals) if real_vals else 1.0\n",
    "\n",
    "    print(f\"\\n{metric_name}:\")\n",
    "    print(f\"  {'Class':<18} {'Median':>9} {'Mean':>9} {'vs Real':>9} {'p-value':>10} {'Signal?':>10}\")\n",
    "    print(f\"  {'-'*68}\")\n",
    "\n",
    "    for label, results in FF_RESULTS.items():\n",
    "        vals   = [r[metric_key] for r in results]\n",
    "        median = np.median(vals)\n",
    "        mean   = np.mean(vals)\n",
    "        ratio  = median / max(real_med, 1e-10)\n",
    "\n",
    "        if label != 'real' and real_vals and len(vals) > 1:\n",
    "            _, p = stats.mannwhitneyu(real_vals, vals, alternative='two-sided')\n",
    "            sig  = '‚úÖ YES' if p < 0.05 else ('‚ö†Ô∏è  WEAK' if p < 0.20 else '‚ùå NO')\n",
    "        else:\n",
    "            p, sig = 1.0, '‚Äî'\n",
    "\n",
    "        print(f\"  {label:<18} {median:>9.5f} {mean:>9.5f} {ratio:>9.2f}x \"\n",
    "              f\"{p:>10.4f} {sig:>10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4fb1b-86d3-4526-94ae-a299c0608b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:51:25.104057Z",
     "iopub.status.busy": "2026-02-18T23:51:25.103775Z",
     "iopub.status.idle": "2026-02-18T23:51:26.303998Z",
     "shell.execute_reply": "2026-02-18T23:51:26.303306Z",
     "shell.execute_reply.started": "2026-02-18T23:51:25.104030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ Figure 3: Temporal trajectories (per-frame wdist) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "methods_show = ['real'] + [m for m in FF_METHODS if m in FF_RESULTS][:3]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(methods_show), figsize=(5*len(methods_show), 5))\n",
    "fig.suptitle('Test A: Temporal Profile of Color Distance\\n'\n",
    "             'Real: fluctuates randomly | Fake: persistently elevated?',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "for col, method in enumerate(methods_show):\n",
    "    ax  = axes[col]\n",
    "    res = FF_RESULTS.get(method, [])[:8]\n",
    "    color = COLORS.get(method, '#95a5a6')\n",
    "\n",
    "    all_trajs = []\n",
    "    for r in res:\n",
    "        traj = np.array(r['per_frame_wdist'])\n",
    "        ax.plot(traj, alpha=0.3, linewidth=1, color=color)\n",
    "        all_trajs.append(traj)\n",
    "\n",
    "    if all_trajs:\n",
    "        min_len = min(len(t) for t in all_trajs)\n",
    "        stacked = np.stack([t[:min_len] for t in all_trajs])\n",
    "        mean_t  = stacked.mean(axis=0)\n",
    "        std_t   = stacked.std(axis=0)\n",
    "        x = np.arange(min_len)\n",
    "        ax.plot(mean_t, color='black', linewidth=2.5, label='Mean')\n",
    "        ax.fill_between(x, mean_t-std_t, mean_t+std_t, alpha=0.2, color='black')\n",
    "\n",
    "    overall_mean = np.mean([np.mean(r['per_frame_wdist']) for r in res]) if res else 0\n",
    "    variation    = np.mean([np.std(r['per_frame_wdist'])  for r in res]) if res else 0\n",
    "    ax.set_title(f'{method}\\nmean={overall_mean:.4f}, var={variation:.4f}',\n",
    "                 color=color, fontweight='bold')\n",
    "    ax.set_xlabel('Frame index'); ax.set_ylabel('W-Distance (color)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'test_a_temporal.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úÖ test_a_temporal.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e15981-6d39-4b95-b553-0ea4db782304",
   "metadata": {},
   "source": [
    "## Section 7 ‚Äî Cross-Dataset Validation: Celeb-DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ac664-61a8-44c7-b8bf-0292cd42e493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:51:26.305124Z",
     "iopub.status.busy": "2026-02-18T23:51:26.304850Z",
     "iopub.status.idle": "2026-02-18T23:52:06.497745Z",
     "shell.execute_reply": "2026-02-18T23:52:06.497146Z",
     "shell.execute_reply.started": "2026-02-18T23:51:26.305103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CELEB_RESULTS = {}\n",
    "\n",
    "if CELEB_VIDEOS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"RUNNING ON CELEB-DF v2\")\n",
    "    print(\"=\" * 70)\n",
    "    for split in ['real', 'fake']:\n",
    "        if CELEB_VIDEOS.get(split):\n",
    "            print(f\"\\n[CelebDF_{split}]\")\n",
    "            CELEB_RESULTS[f'CelebDF_{split}'] = analyze_class(\n",
    "                CELEB_VIDEOS[split], f'CelebDF_{split}')\n",
    "            print(f\"  ‚Üí {len(CELEB_RESULTS[f'CelebDF_{split}'])} done\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Celeb-DF not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8cbc2-4544-490b-b489-4aa3c4b4826b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:52:06.498933Z",
     "iopub.status.busy": "2026-02-18T23:52:06.498674Z",
     "iopub.status.idle": "2026-02-18T23:52:07.544068Z",
     "shell.execute_reply": "2026-02-18T23:52:07.543529Z",
     "shell.execute_reply.started": "2026-02-18T23:52:06.498897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if CELEB_RESULTS:\n",
    "    CELEB_COLORS = {'CelebDF_real':'#27ae60', 'CelebDF_fake':'#c0392b',\n",
    "                    'FF_real': COLORS['real'], 'FF_Dfakes': COLORS['Deepfakes']}\n",
    "\n",
    "    compare = {\n",
    "        'FF_real':  FF_RESULTS.get('real', []),\n",
    "        'FF_Dfakes':FF_RESULTS.get('Deepfakes', []),\n",
    "        'CDF_real': CELEB_RESULTS.get('CelebDF_real', []),\n",
    "        'CDF_fake': CELEB_RESULTS.get('CelebDF_fake', []),\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(22, 6))\n",
    "    fig.suptitle('Cross-Dataset Validation ‚Äî FF++ c23 vs Celeb-DF\\n'\n",
    "                 'Does color/flow signal transfer across datasets?',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "\n",
    "    for ax_idx, (key, title) in enumerate([\n",
    "        ('wdist_mean',    'Test A: W-Distance Mean'),\n",
    "        ('temporal_consistency', 'Test A: Temporal Consistency'),\n",
    "        ('boundary_disc', 'Test B: Boundary Discontinuity'),\n",
    "        ('flow_ratio',    'Test B: Flow Ratio'),\n",
    "    ]):\n",
    "        ax = axes[ax_idx]\n",
    "        data_d = {k: [r[key] for r in v] for k, v in compare.items() if v}\n",
    "\n",
    "        groups = list(data_d.keys())\n",
    "        data   = [data_d[g] for g in groups]\n",
    "        cols   = [CELEB_COLORS.get(g, '#95a5a6') for g in groups]\n",
    "\n",
    "        bp = ax.boxplot(data, patch_artist=True,\n",
    "                        medianprops=dict(color='black', linewidth=2))\n",
    "        for patch, c in zip(bp['boxes'], cols):\n",
    "            patch.set_facecolor(c); patch.set_alpha(0.75)\n",
    "        ax.set_xticklabels(groups, rotation=30, ha='right', fontsize=9)\n",
    "        ax.set_title(title, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axvline(2.5, color='gray', linestyle='--', alpha=0.6)\n",
    "\n",
    "        for i, (g, vals) in enumerate(zip(groups, data)):\n",
    "            ax.text(i+1, np.median(vals), f'{np.median(vals):.4f}',\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'cross_dataset.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"‚úÖ cross_dataset.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458a61c-0f59-4997-aa0f-697ba35198bf",
   "metadata": {},
   "source": [
    "## Section 8 ‚Äî Go/No-Go Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a610bf1-271a-4937-a458-e2b0f441e6f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:52:07.545352Z",
     "iopub.status.busy": "2026-02-18T23:52:07.545077Z",
     "iopub.status.idle": "2026-02-18T23:52:07.576551Z",
     "shell.execute_reply": "2026-02-18T23:52:07.575872Z",
     "shell.execute_reply.started": "2026-02-18T23:52:07.545330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"SEMANTIC SIGNAL TEST ‚Äî GO / NO-GO DECISION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "metrics_to_check = [\n",
    "    ('wdist_mean',           'Test A: Color W-Distance'),\n",
    "    ('temporal_consistency', 'Test A: Temporal Consistency'),\n",
    "    ('boundary_disc',        'Test B: Boundary Discontinuity'),\n",
    "    ('flow_ratio',           'Test B: Flow Ratio'),\n",
    "]\n",
    "\n",
    "real_vals_all = {k: [r[k] for r in FF_RESULTS.get('real', [])]\n",
    "                 for k, _ in metrics_to_check}\n",
    "\n",
    "signals_found = []\n",
    "for metric_key, metric_name in metrics_to_check:\n",
    "    real_vals  = real_vals_all[metric_key]\n",
    "    n_sig = 0\n",
    "    details = []\n",
    "    for label in FF_METHODS:\n",
    "        vals = [r[metric_key] for r in FF_RESULTS.get(label, [])]\n",
    "        if not vals or not real_vals:\n",
    "            continue\n",
    "        _, p = stats.mannwhitneyu(real_vals, vals, alternative='two-sided')\n",
    "        ratio = np.median(vals) / max(np.median(real_vals), 1e-10)\n",
    "        if p < 0.05:\n",
    "            n_sig += 1\n",
    "        details.append(f\"{label}={ratio:.2f}x(p={p:.3f})\")\n",
    "\n",
    "    verdict = 'üü¢ SIGNAL' if n_sig >= 2 else ('üü° WEAK' if n_sig >= 1 else 'üî¥ NONE')\n",
    "    if n_sig >= 1:\n",
    "        signals_found.append(metric_key)\n",
    "    print(f\"\\n{metric_name}\")\n",
    "    print(f\"  Significant: {n_sig}/{len(FF_METHODS)} methods ‚Üí {verdict}\")\n",
    "    for d in details:\n",
    "        print(f\"  {d}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL VERDICT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if len(signals_found) >= 2:\n",
    "    print(\"üü¢ GO ‚Äî Content-level signal found\")\n",
    "    print(f\"   Signals: {signals_found}\")\n",
    "    print(\"   V8.0 plan: add these as explicit features on top of pretrained backbone\")\n",
    "elif len(signals_found) >= 1:\n",
    "    print(\"üü° WEAK SIGNAL ‚Äî Partial evidence\")\n",
    "    print(f\"   Signal: {signals_found}\")\n",
    "    print(\"   V8.0 plan: include as auxiliary feature, not primary signal\")\n",
    "else:\n",
    "    print(\"üî¥ NO SIGNAL ‚Äî Content-level analysis insufficient on FF++ c23\")\n",
    "    print(\"   Conclusion: semantic signal requires pretrained backbone\")\n",
    "    print(\"   Next step: Train EfficientNet-B0 baseline (Step 2)\")\n",
    "    print(\"   The pretrained backbone IS the feature extractor ‚Äî no handcrafted signal needed\")\n",
    "\n",
    "# Save\n",
    "summary = {}\n",
    "for metric_key, _ in metrics_to_check:\n",
    "    real_v = [r[metric_key] for r in FF_RESULTS.get('real', [])]\n",
    "    summary[metric_key] = {\n",
    "        label: {\n",
    "            'median': float(np.median([r[metric_key] for r in res])),\n",
    "            'mean':   float(np.mean([r[metric_key] for r in res])),\n",
    "        }\n",
    "        for label, res in FF_RESULTS.items()\n",
    "    }\n",
    "\n",
    "with open(OUTPUT_DIR / 'semantic_results.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"\\n‚úÖ Results saved ‚Üí {OUTPUT_DIR / 'semantic_results.json'}\")\n",
    "print(f\"‚úÖ Plots saved   ‚Üí {PLOTS_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 5454468,
     "datasetId": 3120670,
     "sourceId": 5380830,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10408999,
     "datasetId": 6248577,
     "sourceId": 10125851,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
