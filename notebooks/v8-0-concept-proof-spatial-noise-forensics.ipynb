{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e2eebf-4539-45f7-82b2-d9194d93d2b7",
   "metadata": {},
   "source": [
    "# ðŸ”¬ V8.0 Concept Proof: Spatial Noise Forensics\n",
    "## Three Tests to Validate the New Forensic Hypothesis\n",
    "\n",
    "**Previous finding:** HLL temporal flicker energy does NOT separate real from fake.  \n",
    "Fakes are actually quieter than real videos (0.97x â€” basically identical).\n",
    "\n",
    "**New hypothesis:**  \n",
    "> The forensic signal is *spatial*, not temporal.  \n",
    "> A deepfake has a **sharp noise boundary** where the generated face meets the background.  \n",
    "> This boundary is **persistent** across frames â€” unlike natural texture variation which is random.\n",
    "\n",
    "### Three Tests\n",
    "| Test | Signal | Validates |\n",
    "|------|--------|-----------|\n",
    "| 1 | Noise gradient sharpness (90th pct / median) | Blend boundary exists |\n",
    "| 2 | Frame-to-frame noise correlation | Boundary is persistent (not random) |\n",
    "| 3 | Spatial autocorrelation break | Noise field is discontinuous |\n",
    "\n",
    "### Go/No-Go Criteria\n",
    "- **Green light:** Signal separates real/fake on both FF++ c23 AND Celeb-DF â†’ Build V8.0\n",
    "- **Amber:** Signal works on Celeb-DF but not FF++ c23 â†’ Need compression robustness module  \n",
    "- **Red:** Signal fails on both â†’ Different forensic anchor needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4cb9d-60c3-42e3-92ed-0a1313c1292c",
   "metadata": {},
   "source": [
    "## Section 1 â€” Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb65692-a7d9-4253-8244-33713bb563f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:00:10.118472Z",
     "iopub.status.busy": "2026-02-18T23:00:10.117645Z",
     "iopub.status.idle": "2026-02-18T23:00:12.040201Z",
     "shell.execute_reply": "2026-02-18T23:00:12.039236Z",
     "shell.execute_reply.started": "2026-02-18T23:00:10.118431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, json, random, warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "from scipy.signal import correlate2d\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "OUTPUT_DIR = Path('/kaggle/working/v8_concept')\n",
    "PLOTS_DIR  = OUTPUT_DIR / 'plots'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"NumPy {np.__version__}, OpenCV {cv2.__version__}\")\n",
    "print(f\"Outputs â†’ {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c7e5c-c9fb-44c3-8389-37e63695e485",
   "metadata": {},
   "source": [
    "## Section 2 â€” Core Forensic Tools\n",
    "\n",
    "### The Noise Extraction Strategy\n",
    "We suppress image content and reveal processing artifacts using three complementary filters:\n",
    "\n",
    "1. **Gaussian residual** â€” simplest: `noise = frame - GaussianBlur(frame)`\n",
    "2. **Laplacian** â€” second derivative, maximally sensitive to sharp edges in the noise field  \n",
    "3. **SRM high-pass** â€” Steganalysis Rich Model filter, specifically designed to reveal \n",
    "   manipulation artifacts by canceling natural image gradients\n",
    "\n",
    "All three are applied and compared â€” if the signal appears in all three, it's robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d222519-240d-4f43-8e96-f4da6e44c993",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:00:42.441059Z",
     "iopub.status.busy": "2026-02-18T23:00:42.440710Z",
     "iopub.status.idle": "2026-02-18T23:00:42.476959Z",
     "shell.execute_reply": "2026-02-18T23:00:42.476140Z",
     "shell.execute_reply.started": "2026-02-18T23:00:42.441019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ SRM-style high-pass filters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# These 5Ã—5 kernels are from the SRM paper (Fridrich & Kodovsky 2012)\n",
    "# They are designed to suppress image content and amplify manipulation residuals\n",
    "\n",
    "SRM_FILTERS = {\n",
    "    'srm1': np.array([\n",
    "        [ 0,  0, 0,  0, 0],\n",
    "        [ 0, -1, 2, -1, 0],\n",
    "        [ 0,  2,-4,  2, 0],\n",
    "        [ 0, -1, 2, -1, 0],\n",
    "        [ 0,  0, 0,  0, 0]], dtype=np.float32) / 4.0,\n",
    "\n",
    "    'srm2': np.array([\n",
    "        [-1,  2, -2,  2, -1],\n",
    "        [ 2, -6,  8, -6,  2],\n",
    "        [-2,  8,-12,  8, -2],\n",
    "        [ 2, -6,  8, -6,  2],\n",
    "        [-1,  2, -2,  2, -1]], dtype=np.float32) / 12.0,\n",
    "\n",
    "    'edge': np.array([\n",
    "        [ 0,  0, -1,  0,  0],\n",
    "        [ 0, -1,  2, -1,  0],\n",
    "        [-1,  2,  0,  2, -1],\n",
    "        [ 0, -1,  2, -1,  0],\n",
    "        [ 0,  0, -1,  0,  0]], dtype=np.float32) / 2.0,\n",
    "}\n",
    "\n",
    "LAPLACIAN = np.array([[0, 1, 0],[1,-4, 1],[0, 1, 0]], dtype=np.float32)\n",
    "\n",
    "\n",
    "def extract_noise_residual(frame_gray: np.ndarray,\n",
    "                            method: str = 'gaussian') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract high-frequency noise residual from a single grayscale frame.\n",
    "    \n",
    "    Args:\n",
    "        frame_gray: (H, W) float32 in [0, 1]\n",
    "        method: 'gaussian' | 'laplacian' | 'srm1' | 'srm2' | 'edge'\n",
    "    Returns:\n",
    "        residual: (H, W) float32 â€” noise field\n",
    "    \"\"\"\n",
    "    if method == 'gaussian':\n",
    "        blurred = cv2.GaussianBlur(frame_gray, (5, 5), 0)\n",
    "        return frame_gray - blurred\n",
    "\n",
    "    elif method == 'laplacian':\n",
    "        lap = cv2.filter2D(frame_gray, -1, LAPLACIAN)\n",
    "        return lap\n",
    "\n",
    "    elif method in SRM_FILTERS:\n",
    "        return cv2.filter2D(frame_gray, -1, SRM_FILTERS[method])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "\n",
    "def frames_to_gray(frames_rgb: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Convert (T, H, W, 3) uint8 to (T, H, W) float32 in [0,1].\"\"\"\n",
    "    return (0.299 * frames_rgb[..., 0].astype(np.float32) +\n",
    "            0.587 * frames_rgb[..., 1].astype(np.float32) +\n",
    "            0.114 * frames_rgb[..., 2].astype(np.float32)) / 255.0\n",
    "\n",
    "\n",
    "# â”€â”€â”€ Self-test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "_test_frame = np.random.rand(112, 112).astype(np.float32)\n",
    "for m in ['gaussian', 'laplacian', 'srm1', 'srm2', 'edge']:\n",
    "    r = extract_noise_residual(_test_frame, m)\n",
    "    print(f\"  {m:12s}: residual shape={r.shape}, std={r.std():.5f}\")\n",
    "print(\"âœ… Noise extraction tools ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719b263-0e85-47bf-9a9a-6c12072cecbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:00:49.101834Z",
     "iopub.status.busy": "2026-02-18T23:00:49.101105Z",
     "iopub.status.idle": "2026-02-18T23:00:49.118776Z",
     "shell.execute_reply": "2026-02-18T23:00:49.117959Z",
     "shell.execute_reply.started": "2026-02-18T23:00:49.101787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ TEST 1: Noise Gradient Sharpness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def noise_gradient_sharpness(frames_rgb: np.ndarray,\n",
    "                              noise_method: str = 'gaussian') -> Dict:\n",
    "    \"\"\"\n",
    "    Measure internal sharpness of the noise field.\n",
    "    \n",
    "    Key metric: 90th_percentile / median of gradient magnitude.\n",
    "    \n",
    "    Real face: noise field is smooth, gradients are small and uniform.\n",
    "               ratio â‰ˆ 2-3x (natural variation)\n",
    "    Deepfake:  noise field has a sharp ring at the blend boundary.\n",
    "               ratio >> 3x (sharp peak against smooth background)\n",
    "    \n",
    "    Returns dict with scalar metrics per video.\n",
    "    \"\"\"\n",
    "    gray = frames_to_gray(frames_rgb)           # (T, H, W)\n",
    "    T = gray.shape[0]\n",
    "    \n",
    "    sharpness_ratios = []\n",
    "    p90_vals, median_vals = [], []\n",
    "    gradient_maps = []\n",
    "    \n",
    "    for t in range(T):\n",
    "        noise = extract_noise_residual(gray[t], noise_method)\n",
    "        # Gradient magnitude of the noise field\n",
    "        gx = cv2.Sobel(noise, cv2.CV_32F, 1, 0, ksize=3)\n",
    "        gy = cv2.Sobel(noise, cv2.CV_32F, 0, 1, ksize=3)\n",
    "        grad_mag = np.sqrt(gx**2 + gy**2)\n",
    "        \n",
    "        p90    = np.percentile(grad_mag, 90)\n",
    "        median = np.median(grad_mag)\n",
    "        ratio  = p90 / max(median, 1e-8)\n",
    "        \n",
    "        sharpness_ratios.append(ratio)\n",
    "        p90_vals.append(p90)\n",
    "        median_vals.append(median)\n",
    "        gradient_maps.append(grad_mag)\n",
    "    \n",
    "    return {\n",
    "        'sharpness_ratio_mean':   float(np.mean(sharpness_ratios)),\n",
    "        'sharpness_ratio_median': float(np.median(sharpness_ratios)),\n",
    "        'sharpness_ratio_std':    float(np.std(sharpness_ratios)),\n",
    "        'p90_mean':               float(np.mean(p90_vals)),\n",
    "        'median_mean':            float(np.mean(median_vals)),\n",
    "        'per_frame_ratios':       sharpness_ratios,\n",
    "        'mean_gradient_map':      np.mean(gradient_maps, axis=0),  # (H, W)\n",
    "    }\n",
    "\n",
    "\n",
    "# â”€â”€â”€ TEST 2: Temporal Persistence â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def temporal_persistence(frames_rgb: np.ndarray,\n",
    "                          noise_method: str = 'gaussian') -> Dict:\n",
    "    \"\"\"\n",
    "    Measure frame-to-frame correlation of the noise residual field.\n",
    "    \n",
    "    Real: noise changes with content â†’ low frame-to-frame correlation\n",
    "    Fake: generator fingerprint is stable â†’ HIGH frame-to-frame correlation\n",
    "    \n",
    "    Key metric: mean Pearson correlation between consecutive noise maps.\n",
    "    \"\"\"\n",
    "    gray  = frames_to_gray(frames_rgb)\n",
    "    T     = gray.shape[0]\n",
    "    \n",
    "    noise_maps = np.stack([extract_noise_residual(gray[t], noise_method)\n",
    "                           for t in range(T)], axis=0)    # (T, H, W)\n",
    "    \n",
    "    # Frame-to-frame Pearson correlation of flattened noise maps\n",
    "    consecutive_corrs = []\n",
    "    for t in range(T - 1):\n",
    "        n1 = noise_maps[t].ravel()\n",
    "        n2 = noise_maps[t + 1].ravel()\n",
    "        # Pearson correlation\n",
    "        corr = np.corrcoef(n1, n2)[0, 1]\n",
    "        consecutive_corrs.append(float(corr) if not np.isnan(corr) else 0.0)\n",
    "    \n",
    "    # Also measure: variance of the MEAN noise map\n",
    "    # High variance in mean = noise is spatially structured (fake)\n",
    "    # Low variance in mean  = noise averages to zero (real, stochastic)\n",
    "    mean_noise_map = noise_maps.mean(axis=0)    # (H, W)\n",
    "    mean_map_var   = float(np.var(mean_noise_map))\n",
    "    \n",
    "    # And: how much does the noise pattern change over time?\n",
    "    # Compute std of each pixel across T, then average\n",
    "    pixel_temporal_std = noise_maps.std(axis=0).mean()\n",
    "    \n",
    "    return {\n",
    "        'consec_corr_mean':    float(np.mean(consecutive_corrs)),\n",
    "        'consec_corr_median':  float(np.median(consecutive_corrs)),\n",
    "        'consec_corr_std':     float(np.std(consecutive_corrs)),\n",
    "        'mean_map_variance':   mean_map_var,\n",
    "        'pixel_temporal_std':  float(pixel_temporal_std),\n",
    "        'per_frame_corrs':     consecutive_corrs,\n",
    "        'mean_noise_map':      mean_noise_map,    # (H, W)\n",
    "    }\n",
    "\n",
    "\n",
    "# â”€â”€â”€ TEST 3: Spatial Autocorrelation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def spatial_autocorrelation(frames_rgb: np.ndarray,\n",
    "                             noise_method: str = 'gaussian',\n",
    "                             lags: List[int] = [1, 3, 5, 10, 20]) -> Dict:\n",
    "    \"\"\"\n",
    "    Measure spatial autocorrelation of the noise field at multiple distances.\n",
    "    \n",
    "    Real face: noise is spatially correlated at short distances (camera sensor)\n",
    "               correlation decays smoothly with distance.\n",
    "    Deepfake:  noise field has a sharp break at the blend boundary.\n",
    "               autocorrelation drops suddenly at the boundary distance.\n",
    "    \n",
    "    We measure: for each lag d, correlation between noise(x,y) and noise(x+d,y).\n",
    "    A sharp drop in the autocorrelation profile indicates a spatial discontinuity.\n",
    "    \"\"\"\n",
    "    gray = frames_to_gray(frames_rgb)\n",
    "    T    = gray.shape[0]\n",
    "    H, W = gray.shape[1], gray.shape[2]\n",
    "    \n",
    "    all_lag_corrs = {d: [] for d in lags}\n",
    "    \n",
    "    for t in range(T):\n",
    "        noise = extract_noise_residual(gray[t], noise_method)\n",
    "        noise_flat = noise - noise.mean()    # zero-mean\n",
    "        \n",
    "        for d in lags:\n",
    "            if d >= W:\n",
    "                continue\n",
    "            # Horizontal lag-d correlation\n",
    "            n1 = noise_flat[:, :-d].ravel()\n",
    "            n2 = noise_flat[:,  d:].ravel()\n",
    "            if len(n1) < 10:\n",
    "                continue\n",
    "            corr = np.corrcoef(n1, n2)[0, 1]\n",
    "            if not np.isnan(corr):\n",
    "                all_lag_corrs[d].append(float(corr))\n",
    "    \n",
    "    lag_means = {d: float(np.mean(v)) if v else 0.0\n",
    "                 for d, v in all_lag_corrs.items()}\n",
    "    \n",
    "    # Autocorrelation decay rate: how fast does correlation drop with distance?\n",
    "    lag_vals   = [lag_means[d] for d in lags]\n",
    "    decay_rate = (lag_vals[0] - lag_vals[-1]) / max(lags[-1] - lags[0], 1)\n",
    "    \n",
    "    # Sharpness of decay: std of differences between consecutive lags\n",
    "    diffs         = np.diff(lag_vals)\n",
    "    decay_std     = float(np.std(diffs))\n",
    "    \n",
    "    return {\n",
    "        'lag_means':    lag_means,\n",
    "        'decay_rate':   decay_rate,\n",
    "        'decay_std':    decay_std,   # high = irregular/sharp decay = boundary\n",
    "        'lag_profile':  lag_vals,\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… All three test functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356bb324-5b50-4ffa-b2c8-82f88c718412",
   "metadata": {},
   "source": [
    "## Section 3 â€” Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d84f2-4989-4bde-9ca6-dfaadba1c1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:00:56.476428Z",
     "iopub.status.busy": "2026-02-18T23:00:56.475667Z",
     "iopub.status.idle": "2026-02-18T23:01:36.607451Z",
     "shell.execute_reply": "2026-02-18T23:01:36.606643Z",
     "shell.execute_reply.started": "2026-02-18T23:00:56.476398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Dataset discovery â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "KAGGLE_INPUT = Path('/kaggle/input')\n",
    "N_SAMPLE     = 20\n",
    "FACE_SIZE    = 112\n",
    "N_FRAMES     = 32\n",
    "\n",
    "def locate_root(base, known_path_parts, marker_dirs):\n",
    "    \"\"\"Find a dataset root by known path or by presence of marker subdirs.\"\"\"\n",
    "    known = base\n",
    "    for part in known_path_parts:\n",
    "        known = known / part\n",
    "    if known.exists():\n",
    "        return known\n",
    "    for d in sorted(base.rglob('*')):\n",
    "        if d.is_dir():\n",
    "            hits = sum(1 for m in marker_dirs if (d / m).exists())\n",
    "            if hits >= len(marker_dirs) // 2 + 1:\n",
    "                return d\n",
    "    return None\n",
    "\n",
    "FF_METHODS = ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures',\n",
    "              'FaceShifter', 'DeepFakeDetection']\n",
    "\n",
    "FF_ROOT = locate_root(KAGGLE_INPUT,\n",
    "    ['datasets','xdxd003','ff-c23','FaceForensics++_C23'],\n",
    "    FF_METHODS)\n",
    "\n",
    "CELEB_ROOT = locate_root(KAGGLE_INPUT,\n",
    "    ['datasets','reubensuju','celeb-df-v2'],\n",
    "    ['Celeb-real','Celeb-synthesis'])\n",
    "\n",
    "print(f\"FF++    root: {FF_ROOT}\")\n",
    "print(f\"Celeb-DF root: {CELEB_ROOT}\")\n",
    "\n",
    "# â”€â”€â”€ Build video lists â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FF_VIDEOS   = {}\n",
    "CELEB_VIDEOS = {}\n",
    "\n",
    "if FF_ROOT:\n",
    "    real_paths = list(FF_ROOT.rglob('original*/*.mp4'))\n",
    "    if not real_paths:\n",
    "        real_paths = [p for p in FF_ROOT.rglob('*.mp4') if 'original' in str(p).lower()]\n",
    "    FF_VIDEOS['real'] = sorted(real_paths)\n",
    "    for m in FF_METHODS:\n",
    "        paths = list((FF_ROOT / m).glob('*.mp4')) if (FF_ROOT / m).exists() else []\n",
    "        if paths:\n",
    "            FF_VIDEOS[m] = sorted(paths)\n",
    "    for k, v in FF_VIDEOS.items():\n",
    "        print(f\"  FF++/{k:25s}: {len(v):4d} videos\")\n",
    "\n",
    "if CELEB_ROOT:\n",
    "    CELEB_VIDEOS['real'] = (list((CELEB_ROOT / 'Celeb-real').glob('*.mp4')) +\n",
    "                            list((CELEB_ROOT / 'YouTube-real').glob('*.mp4')))\n",
    "    CELEB_VIDEOS['fake'] = list((CELEB_ROOT / 'Celeb-synthesis').glob('*.mp4'))\n",
    "    for k, v in CELEB_VIDEOS.items():\n",
    "        print(f\"  Celeb-DF/{k:10s}: {len(v):4d} videos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07db147-2484-4332-960f-c5cb36708165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:01:40.085360Z",
     "iopub.status.busy": "2026-02-18T23:01:40.085105Z",
     "iopub.status.idle": "2026-02-18T23:01:43.451915Z",
     "shell.execute_reply": "2026-02-18T23:01:43.451067Z",
     "shell.execute_reply.started": "2026-02-18T23:01:40.085338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Video loader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_frames(video_path: str, n_frames: int = N_FRAMES,\n",
    "                   size: int = FACE_SIZE) -> Optional[np.ndarray]:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total < n_frames:\n",
    "        cap.release()\n",
    "        return None\n",
    "    indices = np.linspace(0, total - 1, n_frames, dtype=int)\n",
    "    frames  = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Center crop to face region (rough but consistent)\n",
    "        h, w = frame.shape[:2]\n",
    "        margin = 0.10\n",
    "        y1, y2 = int(h * margin), int(h * (1 - margin))\n",
    "        x1, x2 = int(w * 0.15), int(w * 0.85)\n",
    "        frame = frame[y1:y2, x1:x2]\n",
    "        frame = cv2.resize(frame, (size, size))\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    if len(frames) < n_frames // 2:\n",
    "        return None\n",
    "    while len(frames) < n_frames:\n",
    "        frames.append(frames[-1])\n",
    "    return np.stack(frames[:n_frames], axis=0)\n",
    "\n",
    "\n",
    "def sample(lst, n=N_SAMPLE, seed=SEED):\n",
    "    rng = random.Random(seed)\n",
    "    return rng.sample(lst, min(n, len(lst)))\n",
    "\n",
    "\n",
    "# â”€â”€â”€ Quick load test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if FF_VIDEOS.get('real'):\n",
    "    test_frames = extract_frames(str(FF_VIDEOS['real'][0]))\n",
    "    if test_frames is not None:\n",
    "        print(f\"âœ… Load test OK â€” shape: {test_frames.shape}\")\n",
    "        r = noise_gradient_sharpness(test_frames)\n",
    "        print(f\"   Sharpness ratio: {r['sharpness_ratio_mean']:.3f}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Load test failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e0905-fb68-4444-a031-3de1a3462d65",
   "metadata": {},
   "source": [
    "## Section 4 â€” Run All Three Tests on FF++ c23\n",
    "\n",
    "This is the primary experiment. We run all three tests on 20 videos per class.\n",
    "Runtime: ~8-12 minutes on T4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7baa1f0-7aa3-4ad9-a25d-b50c3919f1fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:01:43.454301Z",
     "iopub.status.busy": "2026-02-18T23:01:43.453955Z",
     "iopub.status.idle": "2026-02-18T23:16:34.979458Z",
     "shell.execute_reply": "2026-02-18T23:16:34.978527Z",
     "shell.execute_reply.started": "2026-02-18T23:01:43.454279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Master analysis function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "NOISE_METHOD = 'gaussian'   # primary; we'll compare all methods in Section 6\n",
    "\n",
    "def analyze_class(video_paths: list, label: str,\n",
    "                  n: int = N_SAMPLE, verbose: bool = True) -> List[Dict]:\n",
    "    results = []\n",
    "    sampled = sample(video_paths, n)\n",
    "    \n",
    "    for i, vpath in enumerate(sampled):\n",
    "        frames = extract_frames(str(vpath))\n",
    "        if frames is None:\n",
    "            continue\n",
    "        \n",
    "        t1 = noise_gradient_sharpness(frames, NOISE_METHOD)\n",
    "        t2 = temporal_persistence(frames, NOISE_METHOD)\n",
    "        t3 = spatial_autocorrelation(frames, NOISE_METHOD)\n",
    "        \n",
    "        results.append({\n",
    "            'label':  label,\n",
    "            'video':  Path(vpath).name,\n",
    "            # Test 1\n",
    "            'sharpness_ratio':    t1['sharpness_ratio_mean'],\n",
    "            'p90':                t1['p90_mean'],\n",
    "            'per_frame_ratios':   t1['per_frame_ratios'],\n",
    "            'mean_gradient_map':  t1['mean_gradient_map'],\n",
    "            # Test 2\n",
    "            'consec_corr':        t2['consec_corr_mean'],\n",
    "            'mean_map_var':       t2['mean_map_variance'],\n",
    "            'pixel_temporal_std': t2['pixel_temporal_std'],\n",
    "            'per_frame_corrs':    t2['per_frame_corrs'],\n",
    "            'mean_noise_map':     t2['mean_noise_map'],\n",
    "            # Test 3\n",
    "            'lag_profile':        t3['lag_profile'],\n",
    "            'decay_std':          t3['decay_std'],\n",
    "            'decay_rate':         t3['decay_rate'],\n",
    "        })\n",
    "        \n",
    "        if verbose and (i + 1) % 5 == 0:\n",
    "            r = results[-1]\n",
    "            print(f\"  [{label:15s}] {i+1:2d}/{n} | \"\n",
    "                  f\"sharp={r['sharpness_ratio']:.3f} | \"\n",
    "                  f\"corr={r['consec_corr']:.4f} | \"\n",
    "                  f\"decay_std={r['decay_std']:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# â”€â”€â”€ Run on FF++ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 70)\n",
    "print(\"RUNNING ON FF++ c23\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "FF_RESULTS = {}\n",
    "run_order  = ['real'] + [m for m in ['Deepfakes','Face2Face','FaceSwap','NeuralTextures']\n",
    "                          if m in FF_VIDEOS]\n",
    "\n",
    "for label in run_order:\n",
    "    print(f\"\\n[{label}]\")\n",
    "    FF_RESULTS[label] = analyze_class(FF_VIDEOS[label], label)\n",
    "    print(f\"  â†’ {len(FF_RESULTS[label])} videos done\")\n",
    "\n",
    "print(\"\\nâœ… FF++ analysis complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9b889-5ec4-48c5-ac5e-e9626570a364",
   "metadata": {},
   "source": [
    "## Section 5 â€” Results: FF++ c23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272cae8-0bf3-408e-b85d-4605c3e5ec83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:18:56.859644Z",
     "iopub.status.busy": "2026-02-18T23:18:56.859323Z",
     "iopub.status.idle": "2026-02-18T23:18:56.872532Z",
     "shell.execute_reply": "2026-02-18T23:18:56.871632Z",
     "shell.execute_reply.started": "2026-02-18T23:18:56.859619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Color scheme â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "COLORS = {\n",
    "    'real':           '#2ecc71',\n",
    "    'Deepfakes':      '#e74c3c',\n",
    "    'Face2Face':      '#e67e22',\n",
    "    'FaceSwap':       '#9b59b6',\n",
    "    'NeuralTextures': '#3498db',\n",
    "}\n",
    "\n",
    "def get_metric(results_dict, key):\n",
    "    return {k: [r[key] for r in v] for k, v in results_dict.items()}\n",
    "\n",
    "def boxplot_comparison(ax, data_dict, title, ylabel, colors=COLORS):\n",
    "    groups = list(data_dict.keys())\n",
    "    data   = [data_dict[g] for g in groups]\n",
    "    cols   = [colors.get(g, '#95a5a6') for g in groups]\n",
    "    bp = ax.boxplot(data, patch_artist=True,\n",
    "                    medianprops=dict(color='black', linewidth=2.5),\n",
    "                    notch=False)\n",
    "    for patch, c in zip(bp['boxes'], cols):\n",
    "        patch.set_facecolor(c)\n",
    "        patch.set_alpha(0.75)\n",
    "    ax.set_xticklabels([g.replace('NeuralTextures','NeuralTex.') for g in groups],\n",
    "                       rotation=30, ha='right')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    # Annotate medians\n",
    "    for i, (g, vals) in enumerate(zip(groups, data)):\n",
    "        med = np.median(vals)\n",
    "        ax.text(i+1, med, f'{med:.3f}', ha='center', va='bottom',\n",
    "                fontsize=8, fontweight='bold')\n",
    "    return bp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15dd07-a3b0-480e-a204-3595b89037e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:19:17.045037Z",
     "iopub.status.busy": "2026-02-18T23:19:17.044250Z",
     "iopub.status.idle": "2026-02-18T23:19:18.416343Z",
     "shell.execute_reply": "2026-02-18T23:19:18.415649Z",
     "shell.execute_reply.started": "2026-02-18T23:19:17.044978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Figure 1: Three metrics side by side â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('FF++ c23 â€” Three Forensic Signal Tests\\n'\n",
    "             'Does Spatial Noise Analysis Separate Real from Fake?',\n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "sharp  = get_metric(FF_RESULTS, 'sharpness_ratio')\n",
    "corr   = get_metric(FF_RESULTS, 'consec_corr')\n",
    "decay  = get_metric(FF_RESULTS, 'decay_std')\n",
    "\n",
    "boxplot_comparison(axes[0], sharp, \n",
    "    'Test 1: Noise Gradient Sharpness\\n(90th pct / median)',\n",
    "    'Sharpness Ratio (higher = sharper internal peak)')\n",
    "axes[0].set_xlabel('â†’ Higher for fakes if hypothesis holds')\n",
    "\n",
    "boxplot_comparison(axes[1], corr,\n",
    "    'Test 2: Temporal Persistence\\n(frame-to-frame noise correlation)',\n",
    "    'Consecutive Frame Noise Correlation')\n",
    "axes[1].set_xlabel('â†’ Higher for fakes = persistent generator fingerprint')\n",
    "\n",
    "boxplot_comparison(axes[2], decay,\n",
    "    'Test 3: Spatial Autocorrelation Decay Std\\n(irregularity of decay profile)',\n",
    "    'Decay Irregularity (std of lag differences)')\n",
    "axes[2].set_xlabel('â†’ Higher for fakes = sharp spatial discontinuity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'ff_three_tests.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved ff_three_tests.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfec98-90d9-42bd-90a1-3d1afe2b6b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:19:38.405273Z",
     "iopub.status.busy": "2026-02-18T23:19:38.404404Z",
     "iopub.status.idle": "2026-02-18T23:19:38.436136Z",
     "shell.execute_reply": "2026-02-18T23:19:38.435306Z",
     "shell.execute_reply.started": "2026-02-18T23:19:38.405240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Statistical significance table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nðŸ“Š STATISTICAL RESULTS â€” FF++ c23\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "metrics = [\n",
    "    ('sharpness_ratio', 'Test 1: Gradient Sharpness'),\n",
    "    ('consec_corr',     'Test 2: Temporal Persistence'),\n",
    "    ('decay_std',       'Test 3: Autocorr Decay Std'),\n",
    "]\n",
    "\n",
    "for metric_key, metric_name in metrics:\n",
    "    print(f\"\\n{metric_name}:\")\n",
    "    print(f\"  {'Class':<18} {'Mean':>9} {'Median':>9} {'Std':>9} {'vs Real':>9} {'p-value':>10} {'Signal?':>10}\")\n",
    "    print(f\"  {'-'*76}\")\n",
    "    \n",
    "    real_vals = [r[metric_key] for r in FF_RESULTS.get('real', [])]\n",
    "    real_med  = np.median(real_vals) if real_vals else 1.0\n",
    "    \n",
    "    for label, results in FF_RESULTS.items():\n",
    "        vals   = [r[metric_key] for r in results]\n",
    "        mean   = np.mean(vals)\n",
    "        median = np.median(vals)\n",
    "        std    = np.std(vals)\n",
    "        ratio  = median / max(real_med, 1e-10)\n",
    "        \n",
    "        if label != 'real' and real_vals:\n",
    "            _, p = stats.mannwhitneyu(real_vals, vals, alternative='two-sided')\n",
    "            sig  = 'âœ… YES' if p < 0.05 else ('âš ï¸  WEAK' if p < 0.20 else 'âŒ NO')\n",
    "        else:\n",
    "            p, sig = 1.0, 'â€”'\n",
    "        \n",
    "        print(f\"  {label:<18} {mean:>9.4f} {median:>9.4f} {std:>9.4f} \"\n",
    "              f\"{ratio:>9.2f}x {p:>10.4f} {sig:>10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23f354-da90-4fa1-8b0d-938132a4f51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:16:36.373082Z",
     "iopub.status.busy": "2026-02-18T23:16:36.372727Z",
     "iopub.status.idle": "2026-02-18T23:16:40.370392Z",
     "shell.execute_reply": "2026-02-18T23:16:40.369538Z",
     "shell.execute_reply.started": "2026-02-18T23:16:36.373035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Figure 2: Mean gradient heatmaps real vs Deepfakes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "methods_to_show = ['real'] + [m for m in ['Deepfakes','Face2Face','FaceSwap','NeuralTextures']\n",
    "                               if m in FF_RESULTS][:3]\n",
    "\n",
    "fig, axes = plt.subplots(2, len(methods_to_show), figsize=(5*len(methods_to_show), 10))\n",
    "fig.suptitle('Noise Gradient Heatmaps â€” Where is the Blend Boundary?\\n'\n",
    "             'Top: Mean gradient map | Bottom: Mean noise map',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "global_grad_max  = max(\n",
    "    np.mean([r['mean_gradient_map'] for r in FF_RESULTS[m]], axis=0).max()\n",
    "    for m in methods_to_show if FF_RESULTS.get(m))\n",
    "global_noise_max = max(\n",
    "    np.abs(np.mean([r['mean_noise_map'] for r in FF_RESULTS[m]], axis=0)).max()\n",
    "    for m in methods_to_show if FF_RESULTS.get(m))\n",
    "\n",
    "for col, method in enumerate(methods_to_show):\n",
    "    results = FF_RESULTS.get(method, [])\n",
    "    if not results:\n",
    "        continue\n",
    "    \n",
    "    grad_maps  = np.stack([r['mean_gradient_map'] for r in results])\n",
    "    noise_maps = np.stack([r['mean_noise_map']     for r in results])\n",
    "    \n",
    "    avg_grad  = grad_maps.mean(axis=0)\n",
    "    avg_noise = noise_maps.mean(axis=0)\n",
    "    \n",
    "    color = COLORS.get(method, '#95a5a6')\n",
    "    \n",
    "    # Top row: gradient heatmap\n",
    "    ax = axes[0, col]\n",
    "    im = ax.imshow(avg_grad, cmap='hot', vmin=0, vmax=global_grad_max,\n",
    "                   interpolation='bilinear')\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "    median_sharp = np.median([r['sharpness_ratio'] for r in results])\n",
    "    ax.set_title(f'{method}\\nSharpness={median_sharp:.3f}',\n",
    "                 fontweight='bold',\n",
    "                 bbox=dict(facecolor=color, alpha=0.7, boxstyle='round'),\n",
    "                 color='white' if method != 'real' else 'black')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Bottom row: noise field\n",
    "    ax = axes[1, col]\n",
    "    im = ax.imshow(avg_noise, cmap='RdBu_r', \n",
    "                   vmin=-global_noise_max, vmax=global_noise_max,\n",
    "                   interpolation='bilinear')\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "    median_corr = np.median([r['consec_corr'] for r in results])\n",
    "    ax.set_title(f'Noise map\\nCorr={median_corr:.4f}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'ff_heatmaps.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved ff_heatmaps.png\")\n",
    "print(\"\\nðŸ’¡ Key: if deepfake heatmaps show a ring/oval brighter than real â†’ boundary signal confirmed\")\n",
    "print(\"         if all heatmaps look identical â†’ signal doesn't survive c23 compression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2136c1e-239b-4dd7-a16a-64da287606bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:16:40.371849Z",
     "iopub.status.busy": "2026-02-18T23:16:40.371571Z",
     "iopub.status.idle": "2026-02-18T23:16:41.881845Z",
     "shell.execute_reply": "2026-02-18T23:16:41.881018Z",
     "shell.execute_reply.started": "2026-02-18T23:16:40.371814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Figure 3: Temporal trajectory of sharpness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig, axes = plt.subplots(1, len(methods_to_show), figsize=(5*len(methods_to_show), 5))\n",
    "fig.suptitle('Test 2: Temporal Persistence â€” Frame-by-Frame Sharpness Ratio\\n'\n",
    "             'Real: random fluctuation | Fake: persistently elevated?',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "for col, method in enumerate(methods_to_show):\n",
    "    ax  = axes[col]\n",
    "    res = FF_RESULTS.get(method, [])[:8]\n",
    "    color = COLORS.get(method, '#95a5a6')\n",
    "    \n",
    "    all_trajs = []\n",
    "    for r in res:\n",
    "        traj = np.array(r['per_frame_ratios'])\n",
    "        ax.plot(traj, alpha=0.3, linewidth=1, color=color)\n",
    "        all_trajs.append(traj)\n",
    "    \n",
    "    if all_trajs:\n",
    "        min_len = min(len(t) for t in all_trajs)\n",
    "        stacked = np.stack([t[:min_len] for t in all_trajs])\n",
    "        mean_t  = stacked.mean(axis=0)\n",
    "        std_t   = stacked.std(axis=0)\n",
    "        x = np.arange(min_len)\n",
    "        ax.plot(mean_t, color='black', linewidth=2.5, label='Mean')\n",
    "        ax.fill_between(x, mean_t-std_t, mean_t+std_t, alpha=0.2, color='black')\n",
    "        \n",
    "        # Measure persistence: std of the trajectory (low = persistent, high = erratic)\n",
    "        persistence = np.mean([np.std(t) for t in all_trajs])\n",
    "        overall_mean = np.mean([np.mean(t) for t in all_trajs])\n",
    "    else:\n",
    "        persistence, overall_mean = 0, 0\n",
    "    \n",
    "    ax.set_title(f'{method}\\nmean={overall_mean:.2f}, variation={persistence:.2f}',\n",
    "                 color=color, fontweight='bold')\n",
    "    ax.set_xlabel('Frame index')\n",
    "    ax.set_ylabel('Sharpness ratio')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'ff_temporal_trajectory.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved ff_temporal_trajectory.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5f4e1-4872-45f0-8897-6df45565ccf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:16:41.884517Z",
     "iopub.status.busy": "2026-02-18T23:16:41.884244Z",
     "iopub.status.idle": "2026-02-18T23:16:42.632568Z",
     "shell.execute_reply": "2026-02-18T23:16:42.631705Z",
     "shell.execute_reply.started": "2026-02-18T23:16:41.884493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Figure 4: Autocorrelation profiles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "LAGS = [1, 3, 5, 10, 20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "fig.suptitle('Test 3: Spatial Autocorrelation Profile\\n'\n",
    "             'Sharp drop = blend boundary; smooth decay = natural texture',\n",
    "             fontsize=13, fontweight='bold')\n",
    "\n",
    "for method, results in FF_RESULTS.items():\n",
    "    color = COLORS.get(method, '#95a5a6')\n",
    "    profiles = [r['lag_profile'] for r in results]\n",
    "    min_len  = min(len(p) for p in profiles)\n",
    "    profiles = [p[:min_len] for p in profiles]\n",
    "    mean_profile = np.mean(profiles, axis=0)\n",
    "    std_profile  = np.std(profiles, axis=0)\n",
    "    x = LAGS[:min_len]\n",
    "    \n",
    "    ax.plot(x, mean_profile, 'o-', color=color, linewidth=2,\n",
    "            markersize=6, label=method)\n",
    "    ax.fill_between(x,\n",
    "                    mean_profile - std_profile,\n",
    "                    mean_profile + std_profile,\n",
    "                    alpha=0.1, color=color)\n",
    "\n",
    "ax.set_xlabel('Spatial lag (pixels)')\n",
    "ax.set_ylabel('Spatial autocorrelation of noise field')\n",
    "ax.set_title('Autocorrelation Decay by Class')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'ff_autocorrelation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Saved ff_autocorrelation.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11809a55-1f2f-4d73-a857-c31945e421c6",
   "metadata": {},
   "source": [
    "## Section 6 â€” Cross-Dataset Validation: Celeb-DF\n",
    "\n",
    "**The critical test.** If the signal found in FF++ c23 also appears in Celeb-DF  \n",
    "(different generation method, different compression), it's a universal forensic signal.\n",
    "\n",
    "If it only appears in Celeb-DF but not FF++ â†’ compression destroys the signal in c23  \n",
    "â†’ V8.0 needs explicit compression robustness from day one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b9638-27da-4684-b541-5f0b5b6fae33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:16:42.633973Z",
     "iopub.status.busy": "2026-02-18T23:16:42.633702Z",
     "iopub.status.idle": "2026-02-18T23:17:00.539745Z",
     "shell.execute_reply": "2026-02-18T23:17:00.538862Z",
     "shell.execute_reply.started": "2026-02-18T23:16:42.633950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Run on Celeb-DF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "CELEB_RESULTS = {}\n",
    "\n",
    "if CELEB_VIDEOS:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"RUNNING ON CELEB-DF v2\")\n",
    "    print(\"=\" * 70)\n",
    "    for split in ['real', 'fake']:\n",
    "        if CELEB_VIDEOS.get(split):\n",
    "            print(f\"\\n[CelebDF_{split}]\")\n",
    "            CELEB_RESULTS[f'CelebDF_{split}'] = analyze_class(\n",
    "                CELEB_VIDEOS[split], f'CelebDF_{split}')\n",
    "            print(f\"  â†’ {len(CELEB_RESULTS[f'CelebDF_{split}'])} videos done\")\n",
    "else:\n",
    "    print(\"âš ï¸  Celeb-DF not available â€” attach reubensuju/celeb-df-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e591c-c8df-4f68-921a-369e1ef41698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:17:00.541315Z",
     "iopub.status.busy": "2026-02-18T23:17:00.540934Z",
     "iopub.status.idle": "2026-02-18T23:17:01.579685Z",
     "shell.execute_reply": "2026-02-18T23:17:01.578940Z",
     "shell.execute_reply.started": "2026-02-18T23:17:00.541280Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Cross-dataset comparison plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if CELEB_RESULTS:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle('Cross-Dataset Validation â€” Does the Signal Transfer to Celeb-DF?\\n'\n",
    "                 'FF++ c23 (heavy compression) vs Celeb-DF (lighter compression)',\n",
    "                 fontsize=13, fontweight='bold')\n",
    "    \n",
    "    CELEB_COLORS = {'CelebDF_real': '#27ae60', 'CelebDF_fake': '#c0392b'}\n",
    "    all_colors   = {**COLORS, **CELEB_COLORS}\n",
    "    \n",
    "    # Combine FF++ real + Deepfakes + CelebDF for comparison\n",
    "    compare = {\n",
    "        'FF_real':    FF_RESULTS.get('real', []),\n",
    "        'FF_Dfakes':  FF_RESULTS.get('Deepfakes', []),\n",
    "        'CDF_real':   CELEB_RESULTS.get('CelebDF_real', []),\n",
    "        'CDF_fake':   CELEB_RESULTS.get('CelebDF_fake', []),\n",
    "    }\n",
    "    compare_colors = {\n",
    "        'FF_real':   COLORS['real'],\n",
    "        'FF_Dfakes': COLORS['Deepfakes'],\n",
    "        'CDF_real':  CELEB_COLORS['CelebDF_real'],\n",
    "        'CDF_fake':  CELEB_COLORS['CelebDF_fake'],\n",
    "    }\n",
    "    \n",
    "    for ax_idx, (metric_key, title, ylabel) in enumerate([\n",
    "        ('sharpness_ratio', 'Test 1: Gradient Sharpness', 'Sharpness Ratio'),\n",
    "        ('consec_corr',     'Test 2: Temporal Persistence', 'Frame Correlation'),\n",
    "        ('decay_std',       'Test 3: Autocorr Decay Std', 'Decay Irregularity'),\n",
    "    ]):\n",
    "        ax   = axes[ax_idx]\n",
    "        data_d = {k: [r[metric_key] for r in v] for k, v in compare.items() if v}\n",
    "        boxplot_comparison(ax, data_d, title, ylabel, colors=compare_colors)\n",
    "        \n",
    "        # Draw vertical line between FF++ and CDF groups\n",
    "        if len(data_d) > 2:\n",
    "            ax.axvline(2.5, color='gray', linestyle='--', alpha=0.7)\n",
    "            ax.text(1.5, ax.get_ylim()[1]*0.98, 'FF++', ha='center',\n",
    "                    fontsize=9, color='gray')\n",
    "            ax.text(3.5, ax.get_ylim()[1]*0.98, 'Celeb-DF', ha='center',\n",
    "                    fontsize=9, color='gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'cross_dataset_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ… Saved cross_dataset_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0b020-339e-4f5f-bd5b-a409beff42bb",
   "metadata": {},
   "source": [
    "## Section 7 â€” Which Noise Filter Works Best?\n",
    "\n",
    "Testing all five noise extraction methods on 5 real vs 5 Deepfakes videos.  \n",
    "We pick the best filter for V8.0's Stage 1 noise extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c8fe5-63dc-470f-98de-a70847191250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:17:01.580952Z",
     "iopub.status.busy": "2026-02-18T23:17:01.580689Z",
     "iopub.status.idle": "2026-02-18T23:18:56.797719Z",
     "shell.execute_reply": "2026-02-18T23:18:56.796524Z",
     "shell.execute_reply.started": "2026-02-18T23:17:01.580929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Quick filter comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "FILTER_METHODS = ['gaussian', 'laplacian', 'srm1', 'srm2', 'edge']\n",
    "\n",
    "def quick_filter_test(video_paths_real, video_paths_fake, n=5):\n",
    "    results = {m: {'real': [], 'fake': []} for m in FILTER_METHODS}\n",
    "    \n",
    "    for label, vpaths in [('real', video_paths_real), ('fake', video_paths_fake)]:\n",
    "        for vpath in sample(vpaths, n):\n",
    "            frames = extract_frames(str(vpath))\n",
    "            if frames is None:\n",
    "                continue\n",
    "            for method in FILTER_METHODS:\n",
    "                r = noise_gradient_sharpness(frames, method)\n",
    "                results[method][label].append(r['sharpness_ratio_mean'])\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Testing all noise filters (sharpness ratio â€” higher = more signal)...\")\n",
    "print(\"â”€\" * 65)\n",
    "\n",
    "filter_results = None\n",
    "if FF_VIDEOS.get('real') and FF_VIDEOS.get('Deepfakes'):\n",
    "    filter_results = quick_filter_test(FF_VIDEOS['real'], FF_VIDEOS['Deepfakes'])\n",
    "    \n",
    "    print(f\"{'Filter':<14} {'Real median':>12} {'Fake median':>12} {'Ratio':>8} {'p-value':>10}\")\n",
    "    print(\"â”€\" * 60)\n",
    "    \n",
    "    best_method, best_ratio = 'gaussian', 0.0\n",
    "    for method, data in filter_results.items():\n",
    "        real_v = data['real']\n",
    "        fake_v = data['fake']\n",
    "        if not real_v or not fake_v:\n",
    "            continue\n",
    "        real_med = np.median(real_v)\n",
    "        fake_med = np.median(fake_v)\n",
    "        ratio = fake_med / max(real_med, 1e-8)\n",
    "        _, p  = stats.mannwhitneyu(real_v, fake_v, alternative='two-sided') if len(real_v) > 1 else (0, 1.0)\n",
    "        sig   = 'âœ…' if p < 0.05 else ('âš ï¸' if p < 0.2 else 'âŒ')\n",
    "        print(f\"{method:<14} {real_med:>12.4f} {fake_med:>12.4f} {ratio:>8.3f}x {p:>10.4f} {sig}\")\n",
    "        if abs(ratio - 1.0) > abs(best_ratio - 1.0):\n",
    "            best_ratio, best_method = ratio, method\n",
    "    \n",
    "    print(f\"\\nâ†’ Best filter: {best_method} (ratio={best_ratio:.3f}x)\")\n",
    "    print(f\"  Recommendation for V8.0 Stage 1: use '{best_method}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c416d9f-f598-4f34-be63-710cfdc78226",
   "metadata": {},
   "source": [
    "## Section 8 â€” Summary & Go/No-Go Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e0bafa-af39-4927-bcae-4286578ee94c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:18:56.799432Z",
     "iopub.status.busy": "2026-02-18T23:18:56.799090Z",
     "iopub.status.idle": "2026-02-18T23:18:56.832877Z",
     "shell.execute_reply": "2026-02-18T23:18:56.832072Z",
     "shell.execute_reply.started": "2026-02-18T23:18:56.799398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Auto-generate Go/No-Go report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 70)\n",
    "print(\"V8.0 CONCEPT PROOF â€” GO / NO-GO DECISION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "for metric_key, test_name, direction in [\n",
    "    ('sharpness_ratio', 'Test 1: Gradient Sharpness',    'higher_fake'),\n",
    "    ('consec_corr',     'Test 2: Temporal Persistence',  'higher_fake'),\n",
    "    ('decay_std',       'Test 3: Autocorr Decay Std',    'higher_fake'),\n",
    "]:\n",
    "    real_vals = [r[metric_key] for r in FF_RESULTS.get('real', [])]\n",
    "    real_med  = np.median(real_vals) if real_vals else 0\n",
    "    \n",
    "    method_results = {}\n",
    "    for label in ['Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']:\n",
    "        vals = [r[metric_key] for r in FF_RESULTS.get(label, [])]\n",
    "        if not vals:\n",
    "            continue\n",
    "        fake_med = np.median(vals)\n",
    "        ratio    = fake_med / max(real_med, 1e-10)\n",
    "        _, p     = stats.mannwhitneyu(real_vals, vals, alternative='two-sided') if real_vals else (0,1)\n",
    "        method_results[label] = {'ratio': ratio, 'p': p}\n",
    "    \n",
    "    # Signal quality: how many methods separate significantly?\n",
    "    n_sig     = sum(1 for r in method_results.values() if r['p'] < 0.05)\n",
    "    n_methods = len(method_results)\n",
    "    \n",
    "    if n_sig >= 3:\n",
    "        verdict = 'ðŸŸ¢ STRONG SIGNAL'\n",
    "    elif n_sig >= 1:\n",
    "        verdict = 'ðŸŸ¡ WEAK SIGNAL'\n",
    "    else:\n",
    "        verdict = 'ðŸ”´ NO SIGNAL'\n",
    "    \n",
    "    results_summary[test_name] = {'verdict': verdict, 'n_sig': n_sig, 'n_total': n_methods}\n",
    "    print(f\"\\n{test_name}\")\n",
    "    print(f\"  Significant separation: {n_sig}/{n_methods} methods\")\n",
    "    print(f\"  Verdict: {verdict}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL DECISION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "green = sum(1 for v in results_summary.values() if 'ðŸŸ¢' in v['verdict'])\n",
    "yellow = sum(1 for v in results_summary.values() if 'ðŸŸ¡' in v['verdict'])\n",
    "\n",
    "if green >= 2:\n",
    "    decision = \"ðŸŸ¢ GO â€” Build V8.0 around spatial noise forensics\"\n",
    "    path     = \"Primary: noise gradient sharpness + temporal persistence\"\n",
    "elif green >= 1 or yellow >= 2:\n",
    "    decision = \"ðŸŸ¡ CONDITIONAL GO â€” Signal exists but weak on FF++ c23\"\n",
    "    path     = \"Need: compression robustness module in V8.0 Stage 1\"\n",
    "else:\n",
    "    decision = \"ðŸ”´ NO-GO â€” Spatial noise signal insufficient on FF++ c23\"\n",
    "    path     = \"Need: test on Celeb-DF / raw FF++ / try identity drift\"\n",
    "\n",
    "print(f\"\\n{decision}\")\n",
    "print(f\"Architecture path: {path}\")\n",
    "\n",
    "# Celeb-DF verdict\n",
    "if CELEB_RESULTS:\n",
    "    cdf_real = [r['sharpness_ratio'] for r in CELEB_RESULTS.get('CelebDF_real', [])]\n",
    "    cdf_fake = [r['sharpness_ratio'] for r in CELEB_RESULTS.get('CelebDF_fake', [])]\n",
    "    if cdf_real and cdf_fake:\n",
    "        _, p_cdf = stats.mannwhitneyu(cdf_real, cdf_fake, alternative='two-sided')\n",
    "        ratio_cdf = np.median(cdf_fake) / max(np.median(cdf_real), 1e-10)\n",
    "        print(f\"\\nCeleb-DF sharpness ratio: {ratio_cdf:.3f}x (p={p_cdf:.4f})\")\n",
    "        if p_cdf < 0.05 and ratio_cdf > 1.1:\n",
    "            print(\"ðŸŸ¢ Signal survives in Celeb-DF â†’ universal, not codec-specific\")\n",
    "        elif p_cdf < 0.05:\n",
    "            print(\"ðŸŸ¡ Weak signal in Celeb-DF\")\n",
    "        else:\n",
    "            print(\"ðŸ”´ No signal in Celeb-DF either â†’ different forensic anchor needed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4dd040-c571-43f4-926a-d50f1bb15078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T23:18:56.834892Z",
     "iopub.status.busy": "2026-02-18T23:18:56.834091Z",
     "iopub.status.idle": "2026-02-18T23:18:56.856894Z",
     "shell.execute_reply": "2026-02-18T23:18:56.856018Z",
     "shell.execute_reply.started": "2026-02-18T23:18:56.834865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ Save all results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def to_json_safe(obj):\n",
    "    if isinstance(obj, np.ndarray): return obj.tolist()\n",
    "    if isinstance(obj, (np.float32, np.float64, np.float16)): return float(obj)\n",
    "    if isinstance(obj, (np.int32, np.int64)): return int(obj)\n",
    "    return obj\n",
    "\n",
    "def summarize(results_dict):\n",
    "    out = {}\n",
    "    for label, results in results_dict.items():\n",
    "        out[label] = {\n",
    "            'sharpness_ratio': {\n",
    "                'mean':   float(np.mean([r['sharpness_ratio'] for r in results])),\n",
    "                'median': float(np.median([r['sharpness_ratio'] for r in results])),\n",
    "                'std':    float(np.std([r['sharpness_ratio'] for r in results])),\n",
    "            },\n",
    "            'consec_corr': {\n",
    "                'mean':   float(np.mean([r['consec_corr'] for r in results])),\n",
    "                'median': float(np.median([r['consec_corr'] for r in results])),\n",
    "            },\n",
    "            'decay_std': {\n",
    "                'mean':   float(np.mean([r['decay_std'] for r in results])),\n",
    "                'median': float(np.median([r['decay_std'] for r in results])),\n",
    "            },\n",
    "        }\n",
    "    return out\n",
    "\n",
    "final_results = {\n",
    "    'ff_plus_plus': summarize(FF_RESULTS),\n",
    "    'celeb_df':     summarize(CELEB_RESULTS) if CELEB_RESULTS else {},\n",
    "    'decision':     results_summary,\n",
    "}\n",
    "\n",
    "out_path = OUTPUT_DIR / 'v8_concept_results.json'\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(final_results, f, indent=2, default=to_json_safe)\n",
    "\n",
    "print(f\"âœ… Results saved â†’ {out_path}\")\n",
    "print(f\"âœ… Plots saved   â†’ {PLOTS_DIR}\")\n",
    "print(\"\\nðŸ Concept proof complete. Share the JSON + plots to decide V8.0 architecture.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 5454468,
     "datasetId": 3120670,
     "sourceId": 5380830,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10408999,
     "datasetId": 6248577,
     "sourceId": 10125851,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
