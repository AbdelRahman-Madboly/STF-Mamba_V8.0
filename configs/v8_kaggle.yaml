# =============================================================================
# STF-Mamba V8.0 -- Kaggle T4 x2 Configuration
# =============================================================================
# Platform: Kaggle (2x NVIDIA T4, 15GB VRAM each)
# Training: 25 epochs, batch_size=8
# Purpose: Stage 4 smoke test + Stage 5 full Kaggle run
# =============================================================================

# --- Model Architecture ---
model:
  backbone: "dinov2_vitb14"
  backbone_dim: 768
  freeze_blocks: 10
  finetune_blocks: 2

  temporal_proj_dim: 512
  temporal_num_blocks: 2

  hydra:
    d_state: 64
    d_conv: 7
    expand: 2
    dropout: 0.1
    use_shift: true

  consistency_head:
    input_dim: 513                       # 512 (mean pool) + 1 (variance)
    num_classes: 2

# --- Data ---
data:
  frames_per_clip: 32
  img_size: 224
  face_crop_expand: 1.3

  ff_root: "/kaggle/input/faceforensics"
  celeb_df_root: "/kaggle/input/celeb-df-v2"
  splits_dir: "splits"
  crop_cache_dir: "cache/crops"
  landmark_cache_dir: "cache/landmarks"
  sbi_cache_dir: "cache/sbi"
  sbi_regen_interval: 30

  batch_size: 8
  num_workers: 0                         # MUST be 0 on Kaggle (deadlock)
  pin_memory: true

# --- Training ---
training:
  epochs: 25
  grad_clip: 1.0

  lr_backbone: 5.0e-6
  lr_temporal: 1.0e-4
  lr_head: 1.0e-4

  optimizer: "adamw"
  weight_decay: 1.0e-4

  warmup_epochs: 3
  scheduler: "cosine"

  label_smoothing: 0.0                   # NEVER > 0 for K=2 (Bug #1)
  lambda_var: 0.1

  checkpoint_dir: "checkpoints"
  save_every_n_epochs: 10
  save_best_metric: "val_auc"

  use_dataparallel: true

# --- Evaluation ---
evaluation:
  eval_ff_val: true
  eval_ff_test: false
  eval_celeb_df: true
  eval_dfdc: false

# --- Logging ---
logging:
  print_every_n_batches: 50
  log_variance_gap: true
  save_plots: true
